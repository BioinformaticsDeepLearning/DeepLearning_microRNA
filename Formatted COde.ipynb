{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#importing Libraries used \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "##usefull preprocessing and etc classes\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "##ml model classes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "##importing Feature selection Classes\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Machine learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LogisticModel(xTrain, yTrain, xTest, yTest):\n",
    "    logreg = LogisticRegression(C=1e5)\n",
    "   \n",
    "    logreg.fit(xTrain,yTrain)\n",
    "    yPredict = logreg.predict(xTest)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    score =logreg.score(xTest, yTest)\n",
    "    return  logreg,score, precisionScore,recall, tn, fp, fn, tp, yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNNModel(xTrain, yTrain, xTest, yTest):\n",
    "    neighModel = KNeighborsClassifier(n_neighbors=5)\n",
    "    neighModel.fit(xTrain,yTrain)\n",
    "    \n",
    "    yPredict = neighModel.predict(xTest)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    score =neighModel.score(xTest, yTest)\n",
    "    return  neighModel, score, precisionScore,recall, tn, fp, fn, tp, yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NNModelFunction(xTrain, yTrain, xTest, yTest, DenseNumber):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(16, activation='sigmoid', input_dim=DenseNumber))\n",
    "\n",
    "    model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model2.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "    model2.fit(xTrain,yTrain, epochs=60, batch_size=128)\n",
    "   \n",
    "    scores= model2.evaluate(xTest, yTest)\n",
    "    \n",
    "    yPredict = model2.predict_classes(xTest, batch_size=128)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    \n",
    "    \n",
    "\n",
    "    return model2,scores[1], precisionScore,recall, tn, fp, fn, tp, yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DNN(np.array(X_train), np.array(y_train),  np.array(X_test),\n",
    "#             np.array(y_test) ,X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boostingalgo(xTrain, yTrain, xTest, yTest):\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0).fit(xTrain, yTrain)\n",
    "    \n",
    "    yPredict = clf.predict(xTest)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    score =clf.score(xTest, yTest)\n",
    "    return  clf, score, precisionScore,recall, tn, fp, fn, tp, yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomForestModel(xTrain, yTrain, xTest, yTest):\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    \n",
    "    \n",
    "    yPredict = clf.predict(xTest)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    score =clf.score(xTest, yTest)\n",
    "    return  clf, score, precisionScore,recall, tn, fp, fn, tp, yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientboostingModel(xTrain, yTrain, xTest, yTest):\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0).fit(xTrain, yTrain)\n",
    "    \n",
    "    yPredict = clf.predict(xTest)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    score =clf.score(xTest, yTest)\n",
    "    return  clf, score, precisionScore,recall, tn, fp, fn, tp, yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bernoModel(xTrain, yTrain, xTest, yTest):\n",
    "    \n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    yPredict = clf.predict(xTest)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    score =clf.score(xTest, yTest)\n",
    "    return  clf, score, precisionScore,recall, tn, fp, fn, tp, yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DecisionTreeModel(xTrain, yTrain, xTest, yTest):\n",
    "    treeClas= tree.DecisionTreeClassifier()\n",
    "   \n",
    "    treeClas.fit(xTrain,yTrain)\n",
    "   \n",
    "    yPredict = treeClas.predict(xTest)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    score =treeClas.score(xTest, yTest)\n",
    "    return  treeClas,score, precisionScore,recall, tn, fp, fn, tp,yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVMModel(xTrain, yTrain, xTest, yTest):\n",
    "    svmTModel = svm.SVC()\n",
    "   \n",
    "    svmTModel.fit(xTrain,yTrain)\n",
    "    \n",
    "    yPredict = svmTModel.predict(xTest)\n",
    "    precisionScore=precision_score(yTest, yPredict, average=\"binary\")\n",
    "    tn, fp, fn, tp = confusion_matrix(yTest, yPredict).ravel()\n",
    "    recall=recall_score(yTest, yPredict)\n",
    "    score =svmTModel.score(xTest, yTest)\n",
    "    return  svmTModel, score, precisionScore,recall, tn, fp, fn, tp, yPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VarianceThresholdMethod(Input, output):\n",
    "    selectionModel =VarianceThreshold(threshold=0)\n",
    "    selectionModel.fit(Input, output)\n",
    "    indexes=selectionModel.get_support(indices=True)\n",
    "    columns=list(Input.columns)\n",
    "    selectedList =[]\n",
    "    for i in indexes:\n",
    "        selectedList.append(columns[i])\n",
    "    return selectedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi `Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ChiSqure(Input, output):\n",
    "    model = SelectKBest(chi2, k=10)\n",
    "    temp =Input.copy()\n",
    "    temp=temp.drop([\"POS1\",\"POS7\",  \"m/e\"  , \"POS9\" ,\"POS8\",\"POS4\",\"POS3\",\"POS2\",\"POS9\",\"POS4\",\"POS10\"\n",
    "               ,\"POS6\",\"Energy\", \"POS5\",\"PyloP_Flanking\",\"PhyloP_Stem\"], axis=1)\n",
    "    model.fit(temp, output)\n",
    "    indexes= model.get_support(indices=True)\n",
    "    columns=list(temp.columns)\n",
    "    selectedList =[]\n",
    "    for i in indexes:\n",
    "        selectedList.append(columns[i])\n",
    "    return selectedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RecursiveFeatureEmlination(Input, output):\n",
    "    svc = SVC(kernel=\"linear\", C=1)\n",
    "    rfe = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
    "    rfe.fit(Input, output)\n",
    "    indexes= rfe.get_support(indices=True)\n",
    "    columns=list(Input.columns)\n",
    "    selectedList =[]\n",
    "    for i in indexes:\n",
    "        selectedList.append(columns[i])\n",
    "    return selectedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RLRFeatureSelection(Input, output):\n",
    "    clf = RandomizedLogisticRegression()\n",
    "    clf = clf.fit(Input, output)\n",
    "    indexes=clf.get_support(indices=True)\n",
    "    columns=list(Input.columns)\n",
    "    selectedList =[]\n",
    "    for i in indexes:\n",
    "        selectedList.append(columns[i])\n",
    "    return selectedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treeBasedSelection(Input, output):\n",
    "    clf = ExtraTreesClassifier()\n",
    "    clf = clf.fit(Input, output)\n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    indexes=model.get_support(indices=True)\n",
    "    columns=list(Input.columns)\n",
    "    selectedList =[]\n",
    "    for i in indexes:\n",
    "        selectedList.append(columns[i])\n",
    "    return selectedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lesso(Input, outout):\n",
    "    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(Input, output)\n",
    "    model = SelectFromModel(lsvc, prefit=True)\n",
    "    columns=list(Input.columns)\n",
    "    indexes = list(model.get_support(indices=True))\n",
    "    selectedList =[]\n",
    "    for i in indexes:\n",
    "        selectedList.append(columns[i])\n",
    "    return selectedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"prepocessed_numeric_fullDataSet.csv\")\n",
    "Input=(df.loc[:, df.columns != 'seed'])\n",
    "output = (df['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Applying deep learning on lasso selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "one=lesso(Input, output)\n",
    "two=lesso(Input, output)\n",
    "three=lesso(Input, output)\n",
    "commonLassoFeatures=list(set(one)&set(two)&set(three))\n",
    "print(len(commonLassoFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Input[commonLassoFeatures],output, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35736, 19)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "35736/35736 [==============================] - 3s 82us/step - loss: 0.5575 - acc: 0.7359\n",
      "Epoch 2/32\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.3273 - acc: 0.8435\n",
      "Epoch 3/32\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.2858 - acc: 0.8742\n",
      "Epoch 4/32\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.2493 - acc: 0.8990\n",
      "Epoch 5/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.2405 - acc: 0.9213\n",
      "Epoch 6/32\n",
      "35736/35736 [==============================] - 2s 50us/step - loss: 0.1783 - acc: 0.9410\n",
      "Epoch 7/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.1668 - acc: 0.9459\n",
      "Epoch 8/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.1302 - acc: 0.9567\n",
      "Epoch 9/32\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.1277 - acc: 0.9668\n",
      "Epoch 10/32\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.1200 - acc: 0.9698\n",
      "Epoch 11/32\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.1024 - acc: 0.9698\n",
      "Epoch 12/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.1168 - acc: 0.9752\n",
      "Epoch 13/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.0873 - acc: 0.9789\n",
      "Epoch 14/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.0794 - acc: 0.9776\n",
      "Epoch 15/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.1024 - acc: 0.9815\n",
      "Epoch 16/32\n",
      "35736/35736 [==============================] - 2s 58us/step - loss: 0.0900 - acc: 0.9802\n",
      "Epoch 17/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.0922 - acc: 0.9806\n",
      "Epoch 18/32\n",
      "35736/35736 [==============================] - 2s 58us/step - loss: 0.0809 - acc: 0.9793\n",
      "Epoch 19/32\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.0761 - acc: 0.9834\n",
      "Epoch 20/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.1230 - acc: 0.9818\n",
      "Epoch 21/32\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.2091 - acc: 0.9763\n",
      "Epoch 22/32\n",
      "35736/35736 [==============================] - 2s 56us/step - loss: 0.1407 - acc: 0.9781\n",
      "Epoch 23/32\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 1.7085 - acc: 0.8829\n",
      "Epoch 24/32\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.0960 - acc: 0.9836\n",
      "Epoch 25/32\n",
      "35736/35736 [==============================] - 2s 58us/step - loss: 0.1911 - acc: 0.9776\n",
      "Epoch 26/32\n",
      "35736/35736 [==============================] - 2s 56us/step - loss: 0.0914 - acc: 0.9815\n",
      "Epoch 27/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.1611 - acc: 0.9807\n",
      "Epoch 28/32\n",
      "35736/35736 [==============================] - 2s 50us/step - loss: 0.1172 - acc: 0.9853\n",
      "Epoch 29/32\n",
      "35736/35736 [==============================] - 2s 56us/step - loss: 0.1509 - acc: 0.9821\n",
      "Epoch 30/32\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.0785 - acc: 0.9863\n",
      "Epoch 31/32\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 3.4658 - acc: 0.7814\n",
      "Epoch 32/32\n",
      "35736/35736 [==============================] - 2s 56us/step - loss: 10.3061 - acc: 0.3606\n",
      " 5376/15316 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15316/15316 [==============================] - 0s 22us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.models.Sequential at 0x12051f278>,\n",
       " 0.36582658655277961,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 5603,\n",
       " 0,\n",
       " 9713,\n",
       " 0,\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ..., \n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN(np.array(X_train), np.array(y_train),  np.array(X_test),\n",
    "            np.array(y_test) ,X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying all models on Full Datset without using Any Feature selection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separting Data into Testing and Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Input,output, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_Model, LR_score, LR_precisionScore,LR_recall, LR_tn, LR_fp, LR_fn, LR_tp, LR_yPredict=LogisticModel(X_train, \n",
    "                                                                                                       y_train, X_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99784539044136855"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BA_Model, BA_score, BA_precisionScore,BA_recall, BA_tn, BA_fp, BA_fn, BA_tp, BA_yPredict=boostingalgo(X_train,\n",
    "                                                                                                      y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BN_Model, BN_score, BN_precisionScore,BN_recall, BN_tn, BN_fp, BN_fn, BN_tp, BN_yPredict=bernoModel(X_train,\n",
    "                                                                                                    y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79459388874379733"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BN_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT_Model, DT_score, DT_precisionScore,DT_recall, DT_tn, DT_fp, DT_fn, DT_tp, DT_yPredict=DecisionTreeModel(X_train,\n",
    "                                                                                                           y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_Model, SVM_score, SVM_precisionScore,SVM_recall, SVM_tn, SVM_fp, SVM_fn, SVM_tp, SVM_yPredict=SVMModel(X_train,\n",
    "                                                                                                           y_train, X_test, \n",
    "                                                                                                           y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 0.4762 - acc: 0.7703\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.2961 - acc: 0.8989\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.2074 - acc: 0.9426\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.1374 - acc: 0.9703\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0928 - acc: 0.9795\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0632 - acc: 0.9860\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0484 - acc: 0.9871\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0382 - acc: 0.9904\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0348 - acc: 0.9906\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0282 - acc: 0.9925\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0246 - acc: 0.9937\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0252 - acc: 0.9929\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0228 - acc: 0.9937\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0218 - acc: 0.9934\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0201 - acc: 0.9939\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0193 - acc: 0.9943\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0205 - acc: 0.9936\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 20us/step - loss: 0.0153 - acc: 0.9955\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0179 - acc: 0.9949\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0176 - acc: 0.9942\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0152 - acc: 0.9948\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0149 - acc: 0.9957\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 21us/step - loss: 0.0138 - acc: 0.9955\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0138 - acc: 0.9954\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0142 - acc: 0.9952\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.994 - 1s 29us/step - loss: 0.0148 - acc: 0.9950\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0122 - acc: 0.9964\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.0133 - acc: 0.9957\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0115 - acc: 0.9961\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0111 - acc: 0.9966\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0118 - acc: 0.9963\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0110 - acc: 0.9964\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 21us/step - loss: 0.0096 - acc: 0.9967\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0105 - acc: 0.9964\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0169 - acc: 0.9944\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0083 - acc: 0.9974\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0108 - acc: 0.9963\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0099 - acc: 0.9964\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0078 - acc: 0.9973\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0113 - acc: 0.9959\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0089 - acc: 0.9977\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0075 - acc: 0.9975\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0097 - acc: 0.9964\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0090 - acc: 0.9972\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0082 - acc: 0.9977\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 21us/step - loss: 0.0105 - acc: 0.9963\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0077 - acc: 0.9972\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 21us/step - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0073 - acc: 0.9976\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0093 - acc: 0.9971\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0082 - acc: 0.9977\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0071 - acc: 0.9975: 0s - loss: 0.00\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0081 - acc: 0.9973\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0078 - acc: 0.9975\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0078 - acc: 0.9973\n",
      "15316/15316 [==============================] - 1s 46us/step\n"
     ]
    }
   ],
   "source": [
    "NN_Model, NN_score, NN_precisionScore,NN_recall, NN_tn, NN_fp, NN_fn, NN_tp, NN_yPredict=NNModelFunction(np.array(X_train),\n",
    "                                                                                                         np.array(y_train),\n",
    "                                                                                                         np.array(X_test),\n",
    "                                                                                                         np.array(y_test)\n",
    "                                                                                                         ,X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981718464351006"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "35736/35736 [==============================] - 4s 104us/step - loss: 0.4934 - acc: 0.7490\n",
      "Epoch 2/32\n",
      "35736/35736 [==============================] - 2s 60us/step - loss: 0.3015 - acc: 0.8575\n",
      "Epoch 3/32\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.2384 - acc: 0.8966\n",
      "Epoch 4/32\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 0.1775 - acc: 0.9362\n",
      "Epoch 5/32\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.1504 - acc: 0.9575\n",
      "Epoch 6/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.1185 - acc: 0.9636\n",
      "Epoch 7/32\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.1442 - acc: 0.9689\n",
      "Epoch 8/32\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.1031 - acc: 0.9741\n",
      "Epoch 9/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.0860 - acc: 0.9773\n",
      "Epoch 10/32\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.0895 - acc: 0.9791\n",
      "Epoch 11/32\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.0906 - acc: 0.9804\n",
      "Epoch 12/32\n",
      "35736/35736 [==============================] - 2s 49us/step - loss: 0.0664 - acc: 0.9850\n",
      "Epoch 13/32\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.0651 - acc: 0.9835\n",
      "Epoch 14/32\n",
      "35736/35736 [==============================] - 2s 48us/step - loss: 0.0618 - acc: 0.9871\n",
      "Epoch 15/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.1251 - acc: 0.9812\n",
      "Epoch 16/32\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.1078 - acc: 0.9822\n",
      "Epoch 17/32\n",
      "35736/35736 [==============================] - 2s 56us/step - loss: 0.0998 - acc: 0.9865\n",
      "Epoch 18/32\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.0620 - acc: 0.9867\n",
      "Epoch 19/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.1169 - acc: 0.9837\n",
      "Epoch 20/32\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.0883 - acc: 0.9880\n",
      "Epoch 21/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.1299 - acc: 0.9795\n",
      "Epoch 22/32\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 0.0806 - acc: 0.9872\n",
      "Epoch 23/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.0739 - acc: 0.9859\n",
      "Epoch 24/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.0940 - acc: 0.9842\n",
      "Epoch 25/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.0821 - acc: 0.9865\n",
      "Epoch 26/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.0691 - acc: 0.9875\n",
      "Epoch 27/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.1323 - acc: 0.9836\n",
      "Epoch 28/32\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 0.0486 - acc: 0.9905\n",
      "Epoch 29/32\n",
      "35736/35736 [==============================] - 2s 50us/step - loss: 0.0510 - acc: 0.9916\n",
      "Epoch 30/32\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.0591 - acc: 0.9895\n",
      "Epoch 31/32\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.0818 - acc: 0.9886\n",
      "Epoch 32/32\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.0844 - acc: 0.9897\n",
      "15316/15316 [==============================] - 0s 23us/step\n"
     ]
    }
   ],
   "source": [
    "DNN_Model, DNN_score, DNN_precisionScore,DNN_recall, DNN_tn, DNN_fp, DNN_fn, DNN_tp, DNN_yPredict=DNN(np.array(X_train),\n",
    "                                                                                                         np.array(y_train),\n",
    "                                                                                                         np.array(X_test),\n",
    "                                                                                                         np.array(y_test)\n",
    "                                                                                                         ,X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99693131365891874"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature slection and After Feature selection apply ML models on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold APplying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputColumnsVari=VarianceThresholdMethod(Input, output)\n",
    "len(InputColumnsVari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VInput = Input[InputColumnsVari]\n",
    "VX_train, VX_test, Vy_train, Vy_test = train_test_split(VInput,\n",
    "                                                        output, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " 0.99458083050404811,\n",
       " 0.99741735537190079,\n",
       " 0.99402862143519,\n",
       " 5578,\n",
       " 25,\n",
       " 58,\n",
       " 9655,\n",
       " array([0, 0, 0, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNModel(VX_train,Vy_train, VX_test, Vy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       " 0.79459388874379733,\n",
       " 0.85501135257865712,\n",
       " 0.81416658087099758,\n",
       " 4262,\n",
       " 1341,\n",
       " 1805,\n",
       " 7908,\n",
       " array([1, 0, 0, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoModel(VX_train,Vy_train, VX_test, Vy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 0.94332723948811703,\n",
       " 0.91796616576883094,\n",
       " 1.0,\n",
       " 4735,\n",
       " 868,\n",
       " 0,\n",
       " 9713,\n",
       " array([0, 0, 0, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMModel(VX_train,Vy_train, VX_test, Vy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.4968 - acc: 0.8010\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.3643 - acc: 0.8957\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.2436 - acc: 0.9527\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.1584 - acc: 0.9749\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.1001 - acc: 0.9845\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.0690 - acc: 0.9865\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0506 - acc: 0.9887\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0409 - acc: 0.9911\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0378 - acc: 0.9896\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0312 - acc: 0.9915\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0340 - acc: 0.9901\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0324 - acc: 0.9911\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0255 - acc: 0.9924\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0263 - acc: 0.9905\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0233 - acc: 0.9929\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0236 - acc: 0.9930\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0264 - acc: 0.9914\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0180 - acc: 0.9945\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0203 - acc: 0.9925\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0240 - acc: 0.9912\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0178 - acc: 0.9942\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0188 - acc: 0.9934\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0159 - acc: 0.9950\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0176 - acc: 0.9935\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0155 - acc: 0.9942\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0151 - acc: 0.9948\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0243 - acc: 0.9926\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0123 - acc: 0.9962\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0154 - acc: 0.9954\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0137 - acc: 0.9956\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0121 - acc: 0.9964\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.0147 - acc: 0.9958\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0130 - acc: 0.9940\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0154 - acc: 0.9940\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 21us/step - loss: 0.0130 - acc: 0.9959\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0200 - acc: 0.9934\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0145 - acc: 0.9947\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0112 - acc: 0.9960\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0107 - acc: 0.9966\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 25us/step - loss: 0.0105 - acc: 0.9966\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0168 - acc: 0.9943\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0150 - acc: 0.9945\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0099 - acc: 0.9967\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0132 - acc: 0.9964\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0127 - acc: 0.9959\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0110 - acc: 0.9968\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0148 - acc: 0.9955\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0113 - acc: 0.9969\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0107 - acc: 0.9965\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0098 - acc: 0.9961\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0086 - acc: 0.9972\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0113 - acc: 0.9969\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0110 - acc: 0.9963\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 23us/step - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0121 - acc: 0.9960\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0153 - acc: 0.9967\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 24us/step - loss: 0.0094 - acc: 0.9965\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 22us/step - loss: 0.0138 - acc: 0.9957\n",
      "15316/15316 [==============================] - 1s 47us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.models.Sequential at 0x11e0ec5f8>,\n",
       " 0.99869417602507182,\n",
       " 0.99855981894866785,\n",
       " 0.99938227118295064,\n",
       " 5589,\n",
       " 14,\n",
       " 6,\n",
       " 9707,\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ..., \n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=int32))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNModelFunction(np.array(VX_train),Vy_train, \n",
    "                np.array(VX_test), Vy_test, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InputColumns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-3dbdf6735c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m DNN(np.array(VX_train),Vy_train, \n\u001b[0;32m----> 2\u001b[0;31m                 np.array(VX_test), Vy_test, len(InputColumns))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'InputColumns' is not defined"
     ]
    }
   ],
   "source": [
    "DNN(np.array(VX_train),Vy_train, \n",
    "                np.array(VX_test), Vy_test, len(InputColumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneT=treeBasedSelection(Input, output)\n",
    "twoT=treeBasedSelection(Input, output)\n",
    "threeT=treeBasedSelection(Input, output)\n",
    "commonTreeFeatures=list(set(oneT)&set(twoT)&set(threeT))\n",
    "treeInput = Input[commonTreeFeatures]\n",
    "len(commonTreeFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TX_train, TX_test, Ty_train, Ty_test = train_test_split(treeInput,\n",
    "                                                        output, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 0.99771480804387569, 1.0, 0.9963965819005457, 5603, 0, 35, 9678, array([0, 0, 0, ..., 1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(LogisticModel(TX_train,Ty_train, TX_test, Ty_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-cdf2467059dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moneR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRecursiveFeatureEmlination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtwoR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRecursiveFeatureEmlination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mthreeR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRecursiveFeatureEmlination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcommonReFeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwoR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreeR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommonReFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-5aa71ab9a7f4>\u001b[0m in \u001b[0;36mRecursiveFeatureEmlination\u001b[0;34m(Input, output)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oneR=RecursiveFeatureEmlination(Input, output)\n",
    "twoR=RecursiveFeatureEmlination(Input, output)\n",
    "threeR=RecursiveFeatureEmlination(Input, output)\n",
    "commonReFeatures=list(set(oneR)&set(twoR)&set(threeR))\n",
    "len(commonReFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ReInput = Input[commonReFeatures]\n",
    "RX_train, RX_test, Ry_train, Ry_test = train_test_split(ReInput,\n",
    "                                                        output, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(LogisticModel(RX_train,Ry_train, RX_test, Ry_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bernoModel(RX_train,Ry_train, RX_test, Ry_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNNModel(RX_train,Ry_train, RX_test, Ry_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVMModel(RX_train,Ry_train, RX_test, Ry_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NNModelFunction(np.array(RX_train),Ry_train, \n",
    "                np.array(RX_test), Ry_test, len(commonReFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DNN(np.array(RX_train),Ry_train, \n",
    "                np.array(RX_test), Ry_test, len(commonReFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Lasso First and then take that Features and feed through ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one=lesso(Input, output)\n",
    "two=lesso(Input, output)\n",
    "three=lesso(Input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "commonLassoFeatures=list(set(one)&set(two)&set(three))\n",
    "print(len(commonLassoFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LassoInput = np.array(Input[commonLassoFeatures])\n",
    "input_number=len(commonLassoFeatures)\n",
    "input_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf_total = KFold(len(LassoInput), n_folds=10, shuffle=True, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n"
     ]
    }
   ],
   "source": [
    "LR10=[]\n",
    "precisionR10=[]\n",
    "recallR10=[]\n",
    "TruePositive10 =[]\n",
    "FalsePositive10 =[]\n",
    "for train, test in kf_total:\n",
    "    TrainX=pd.DataFrame(LassoInput[list(train),:])\n",
    "    Trainy=pd.DataFrame(output[list(train)])\n",
    "    TestX=pd.DataFrame(LassoInput[list(test),:])\n",
    "    Testy=pd.DataFrame(output[list(test)])\n",
    "    model,score, precision, recall, TN, FP, FN, TP, yPredict=LogisticModel(TrainX, Trainy, TestX,Testy )\n",
    "    LR10.append(score)\n",
    "    precisionR10.append(precision)\n",
    "    recallR10.append(recall)\n",
    "    TruePositive10.append(TP)\n",
    "    FalsePositive10.append(FP)\n",
    "    print(\"!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.998021605048\n",
      "Precision\n",
      "0.999846634591\n",
      "ReCall\n",
      "0.997050783187\n",
      "TruePositive\n",
      "3246.7\n",
      "False Posisive\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:\")\n",
    "print(np.mean(LR10))\n",
    "print(\"Precision\")\n",
    "print(np.mean(precisionR10))\n",
    "print(\"ReCall\")\n",
    "print(np.mean(recallR10))\n",
    "print(\"TruePositive\")\n",
    "print(np.mean(TruePositive10) )\n",
    "print(\"False Posisive\")\n",
    "print(np.mean(FalsePositive10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multivariate Bernoulli Nave Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "Accuracy:\n",
      "0.753094740186\n",
      "Precision\n",
      "0.822995365427\n",
      "ReCall\n",
      "0.780870275847\n",
      "TruePositive\n",
      "2542.7\n",
      "False Posisive\n",
      "546.9\n"
     ]
    }
   ],
   "source": [
    "NB10=[]\n",
    "precisionR10=[]\n",
    "recallR10=[]\n",
    "TruePositive10 =[]\n",
    "FalsePositive10 =[]\n",
    "for train, test in kf_total:\n",
    "    TrainX=pd.DataFrame(LassoInput[list(train),:])\n",
    "    Trainy=pd.DataFrame(output[list(train)])\n",
    "    TestX=pd.DataFrame(LassoInput[list(test),:])\n",
    "    Testy=pd.DataFrame(output[list(test)])\n",
    "    model,score, precision, recall, TN, FP, FN, TP, yPredict=bernoModel(TrainX, Trainy, TestX,Testy )\n",
    "    NB10.append(score)\n",
    "    precisionR10.append(precision)\n",
    "    recallR10.append(recall)\n",
    "    TruePositive10.append(TP)\n",
    "    FalsePositive10.append(FP)\n",
    "    print(\"!!!!!\")\n",
    "\n",
    "print (\"Accuracy:\")\n",
    "print(np.mean(NB10))\n",
    "print(\"Precision\")\n",
    "print(np.mean(precisionR10))\n",
    "print(\"ReCall\")\n",
    "print(np.mean(recallR10))\n",
    "print(\"TruePositive\")\n",
    "print(np.mean(TruePositive10) )\n",
    "print(\"False Posisive\")\n",
    "print(np.mean(FalsePositive10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "!!!!!\n",
      "Accuracy:\n",
      "0.970598711815\n",
      "Precision\n",
      "0.955926592858\n",
      "ReCall\n",
      "1.0\n",
      "TruePositive\n",
      "3256.3\n",
      "False Posisive\n",
      "150.1\n"
     ]
    }
   ],
   "source": [
    "SVM10=[]\n",
    "precisionR10=[]\n",
    "recallR10=[]\n",
    "TruePositive10 =[]\n",
    "FalsePositive10 =[]\n",
    "for train, test in kf_total:\n",
    "    TrainX=pd.DataFrame(LassoInput[list(train),:])\n",
    "    Trainy=pd.DataFrame(output[list(train)])\n",
    "    TestX=pd.DataFrame(LassoInput[list(test),:])\n",
    "    Testy=pd.DataFrame(output[list(test)])\n",
    "    model,score, precision, recall, TN, FP, FN, TP, yPredict=SVMModel(TrainX, Trainy, TestX,Testy )\n",
    "    SVM10.append(score)\n",
    "    precisionR10.append(precision)\n",
    "    recallR10.append(recall)\n",
    "    TruePositive10.append(TP)\n",
    "    FalsePositive10.append(FP)\n",
    "    print(\"!!!!!\")\n",
    "\n",
    "print (\"Accuracy:\")\n",
    "print(np.mean(SVM10))\n",
    "print(\"Precision\")\n",
    "print(np.mean(precisionR10))\n",
    "print(\"ReCall\")\n",
    "print(np.mean(recallR10))\n",
    "print(\"TruePositive\")\n",
    "print(np.mean(TruePositive10) )\n",
    "print(\"False Posisive\")\n",
    "print(np.mean(FalsePositive10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "45946/45946 [==============================] - 2s 37us/step - loss: 0.4236 - acc: 0.8543\n",
      "Epoch 2/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.2710 - acc: 0.9179\n",
      "Epoch 3/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.1608 - acc: 0.9611\n",
      "Epoch 4/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0982 - acc: 0.9789\n",
      "Epoch 5/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0639 - acc: 0.9865\n",
      "Epoch 6/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0448 - acc: 0.9896\n",
      "Epoch 7/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0340 - acc: 0.9907\n",
      "Epoch 8/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0310 - acc: 0.9900\n",
      "Epoch 9/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0267 - acc: 0.9918\n",
      "Epoch 10/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0291 - acc: 0.9909\n",
      "Epoch 11/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0276 - acc: 0.9919\n",
      "Epoch 12/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0228 - acc: 0.9934\n",
      "Epoch 13/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0208 - acc: 0.9932\n",
      "Epoch 14/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0190 - acc: 0.9941\n",
      "Epoch 15/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0190 - acc: 0.9935\n",
      "Epoch 16/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0161 - acc: 0.9943\n",
      "Epoch 17/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0178 - acc: 0.9939\n",
      "Epoch 18/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0176 - acc: 0.9947\n",
      "Epoch 19/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0172 - acc: 0.9937\n",
      "Epoch 20/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0183 - acc: 0.9940\n",
      "Epoch 21/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0135 - acc: 0.9957\n",
      "Epoch 22/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0156 - acc: 0.9933\n",
      "Epoch 23/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0162 - acc: 0.9938\n",
      "Epoch 24/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0145 - acc: 0.9949\n",
      "Epoch 25/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0111 - acc: 0.9957\n",
      "Epoch 26/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0132 - acc: 0.9953\n",
      "Epoch 27/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0116 - acc: 0.9960\n",
      "Epoch 28/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0104 - acc: 0.9963\n",
      "Epoch 29/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0116 - acc: 0.9954\n",
      "Epoch 30/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0090 - acc: 0.9971\n",
      "Epoch 31/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0146 - acc: 0.9947ETA: 0s - loss: 0.0109 \n",
      "Epoch 32/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0118 - acc: 0.9958\n",
      "Epoch 33/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 34/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 35/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0091 - acc: 0.9971\n",
      "Epoch 36/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0082 - acc: 0.9972\n",
      "Epoch 37/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0092 - acc: 0.9971\n",
      "Epoch 38/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 39/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 40/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0087 - acc: 0.9971\n",
      "Epoch 41/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0115 - acc: 0.9965\n",
      "Epoch 42/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0086 - acc: 0.9975\n",
      "Epoch 43/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 44/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 45/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0090 - acc: 0.9969\n",
      "Epoch 46/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0083 - acc: 0.9965\n",
      "Epoch 47/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0086 - acc: 0.9971\n",
      "Epoch 48/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0072 - acc: 0.9978\n",
      "Epoch 49/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0080 - acc: 0.9975\n",
      "Epoch 50/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0094 - acc: 0.9968\n",
      "Epoch 51/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0073 - acc: 0.9975\n",
      "Epoch 52/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0070 - acc: 0.9981\n",
      "Epoch 53/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0068 - acc: 0.9975\n",
      "Epoch 54/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0080 - acc: 0.9971\n",
      "Epoch 55/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0091 - acc: 0.9973\n",
      "Epoch 56/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 57/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 58/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 59/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0071 - acc: 0.9971\n",
      "Epoch 60/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0067 - acc: 0.9977\n",
      "5106/5106 [==============================] - 0s 92us/step\n",
      "!!!!!\n",
      "Epoch 1/60\n",
      "45946/45946 [==============================] - 2s 37us/step - loss: 0.6091 - acc: 0.6961\n",
      "Epoch 2/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.3773 - acc: 0.9339\n",
      "Epoch 3/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.2581 - acc: 0.9668\n",
      "Epoch 4/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.1645 - acc: 0.9791\n",
      "Epoch 5/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.1168 - acc: 0.9872\n",
      "Epoch 6/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0855 - acc: 0.9909\n",
      "Epoch 7/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0635 - acc: 0.9921\n",
      "Epoch 8/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0390 - acc: 0.9931: 0s - loss: 0.0504 - \n",
      "Epoch 9/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0313 - acc: 0.9919\n",
      "Epoch 10/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0261 - acc: 0.9931\n",
      "Epoch 11/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0241 - acc: 0.9936\n",
      "Epoch 12/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0204 - acc: 0.9938\n",
      "Epoch 13/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0188 - acc: 0.9952\n",
      "Epoch 14/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0181 - acc: 0.9950\n",
      "Epoch 15/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0200 - acc: 0.9928\n",
      "Epoch 16/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0184 - acc: 0.9946\n",
      "Epoch 17/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0197 - acc: 0.9929\n",
      "Epoch 18/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0144 - acc: 0.9952\n",
      "Epoch 19/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 20/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0167 - acc: 0.9942\n",
      "Epoch 21/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 22/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0176 - acc: 0.9939\n",
      "Epoch 23/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0149 - acc: 0.9950\n",
      "Epoch 24/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0132 - acc: 0.9957\n",
      "Epoch 25/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0135 - acc: 0.9952\n",
      "Epoch 26/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0135 - acc: 0.9955\n",
      "Epoch 27/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0146 - acc: 0.9956\n",
      "Epoch 28/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 29/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0106 - acc: 0.9970\n",
      "Epoch 30/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0120 - acc: 0.9961\n",
      "Epoch 31/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0105 - acc: 0.9966\n",
      "Epoch 32/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0121 - acc: 0.9951\n",
      "Epoch 33/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0109 - acc: 0.9964\n",
      "Epoch 34/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0091 - acc: 0.9969\n",
      "Epoch 35/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0102 - acc: 0.9967\n",
      "Epoch 36/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0103 - acc: 0.9972\n",
      "Epoch 37/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0083 - acc: 0.9970\n",
      "Epoch 38/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 39/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0091 - acc: 0.9961\n",
      "Epoch 40/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0080 - acc: 0.9971\n",
      "Epoch 41/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0088 - acc: 0.9971\n",
      "Epoch 42/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0085 - acc: 0.9971\n",
      "Epoch 43/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0098 - acc: 0.9970\n",
      "Epoch 44/60\n",
      "45946/45946 [==============================] - 1s 17us/step - loss: 0.0096 - acc: 0.9964\n",
      "Epoch 45/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0090 - acc: 0.9970\n",
      "Epoch 46/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0072 - acc: 0.9976\n",
      "Epoch 47/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0074 - acc: 0.9976\n",
      "Epoch 48/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 49/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0098 - acc: 0.9963\n",
      "Epoch 50/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0086 - acc: 0.9967\n",
      "Epoch 51/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 52/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0086 - acc: 0.9972\n",
      "Epoch 53/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0078 - acc: 0.9969\n",
      "Epoch 54/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0076 - acc: 0.9972\n",
      "Epoch 55/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0057 - acc: 0.9981\n",
      "Epoch 56/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0067 - acc: 0.9974\n",
      "Epoch 57/60\n",
      "45946/45946 [==============================] - 1s 15us/step - loss: 0.0073 - acc: 0.9973\n",
      "Epoch 58/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0067 - acc: 0.9979\n",
      "Epoch 59/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0086 - acc: 0.9968\n",
      "Epoch 60/60\n",
      "45946/45946 [==============================] - 1s 16us/step - loss: 0.0070 - acc: 0.9978\n",
      "5106/5106 [==============================] - 0s 97us/step\n",
      "!!!!!\n",
      "Epoch 1/60\n",
      "45947/45947 [==============================] - 2s 36us/step - loss: 0.3883 - acc: 0.8250\n",
      "Epoch 2/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.2302 - acc: 0.9515\n",
      "Epoch 3/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.1391 - acc: 0.9835\n",
      "Epoch 4/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0835 - acc: 0.9901\n",
      "Epoch 5/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0472 - acc: 0.9928\n",
      "Epoch 6/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0357 - acc: 0.9931\n",
      "Epoch 7/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0289 - acc: 0.9932\n",
      "Epoch 8/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0254 - acc: 0.9938\n",
      "Epoch 9/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0229 - acc: 0.9936\n",
      "Epoch 10/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0194 - acc: 0.9946\n",
      "Epoch 11/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0200 - acc: 0.9946: 0s - loss: 0.0174\n",
      "Epoch 12/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0197 - acc: 0.9939\n",
      "Epoch 13/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0154 - acc: 0.9956\n",
      "Epoch 14/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0143 - acc: 0.9956\n",
      "Epoch 15/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0137 - acc: 0.9959\n",
      "Epoch 16/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0169 - acc: 0.9942\n",
      "Epoch 17/60\n",
      "45947/45947 [==============================] - 1s 18us/step - loss: 0.0138 - acc: 0.9953\n",
      "Epoch 18/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0116 - acc: 0.9964\n",
      "Epoch 19/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0111 - acc: 0.9962\n",
      "Epoch 20/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0119 - acc: 0.9965\n",
      "Epoch 21/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0113 - acc: 0.9962\n",
      "Epoch 22/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0120 - acc: 0.9966\n",
      "Epoch 23/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0134 - acc: 0.9963\n",
      "Epoch 24/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0093 - acc: 0.9972\n",
      "Epoch 25/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0118 - acc: 0.9959\n",
      "Epoch 26/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0116 - acc: 0.9956\n",
      "Epoch 27/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0103 - acc: 0.9968\n",
      "Epoch 28/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 29/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0108 - acc: 0.9964\n",
      "Epoch 30/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0099 - acc: 0.9961\n",
      "Epoch 31/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0104 - acc: 0.9969\n",
      "Epoch 32/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0091 - acc: 0.9974\n",
      "Epoch 33/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0096 - acc: 0.9960\n",
      "Epoch 34/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0114 - acc: 0.9964\n",
      "Epoch 35/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0092 - acc: 0.9970\n",
      "Epoch 36/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0088 - acc: 0.9980\n",
      "Epoch 37/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0107 - acc: 0.9969\n",
      "Epoch 38/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0102 - acc: 0.9960\n",
      "Epoch 39/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0108 - acc: 0.9960\n",
      "Epoch 40/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0109 - acc: 0.9962\n",
      "Epoch 41/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0069 - acc: 0.9978\n",
      "Epoch 42/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0086 - acc: 0.9974\n",
      "Epoch 43/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0081 - acc: 0.9973\n",
      "Epoch 44/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 45/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0076 - acc: 0.9973\n",
      "Epoch 46/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0076 - acc: 0.9973\n",
      "Epoch 47/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0087 - acc: 0.9964\n",
      "Epoch 48/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0080 - acc: 0.9970\n",
      "Epoch 49/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0068 - acc: 0.9977\n",
      "Epoch 50/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 51/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 52/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0083 - acc: 0.9976\n",
      "Epoch 53/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0072 - acc: 0.9972\n",
      "Epoch 54/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0081 - acc: 0.9971\n",
      "Epoch 55/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 56/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 57/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 58/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0062 - acc: 0.9979\n",
      "Epoch 59/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 60/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0074 - acc: 0.9978\n",
      "5105/5105 [==============================] - 1s 99us/step\n",
      "!!!!!\n",
      "Epoch 1/60\n",
      "45947/45947 [==============================] - 2s 37us/step - loss: 0.6135 - acc: 0.6743\n",
      "Epoch 2/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.3095 - acc: 0.9228\n",
      "Epoch 3/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.1748 - acc: 0.9669\n",
      "Epoch 4/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.1017 - acc: 0.9827\n",
      "Epoch 5/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0649 - acc: 0.9872\n",
      "Epoch 6/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0463 - acc: 0.9881\n",
      "Epoch 7/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0389 - acc: 0.9896\n",
      "Epoch 8/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0335 - acc: 0.9909\n",
      "Epoch 9/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0291 - acc: 0.9911\n",
      "Epoch 10/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0304 - acc: 0.9906\n",
      "Epoch 11/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0260 - acc: 0.9916\n",
      "Epoch 12/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0270 - acc: 0.9908\n",
      "Epoch 13/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0217 - acc: 0.9934\n",
      "Epoch 14/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0195 - acc: 0.9938\n",
      "Epoch 15/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0176 - acc: 0.9940\n",
      "Epoch 16/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0157 - acc: 0.9949\n",
      "Epoch 17/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0158 - acc: 0.9954\n",
      "Epoch 18/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0169 - acc: 0.9948\n",
      "Epoch 19/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0138 - acc: 0.9956\n",
      "Epoch 20/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0143 - acc: 0.9956\n",
      "Epoch 21/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0126 - acc: 0.9959\n",
      "Epoch 22/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0120 - acc: 0.9965\n",
      "Epoch 23/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0117 - acc: 0.9965\n",
      "Epoch 24/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0105 - acc: 0.9961\n",
      "Epoch 25/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 26/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 27/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0106 - acc: 0.9967\n",
      "Epoch 28/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0108 - acc: 0.9964\n",
      "Epoch 29/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 30/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0103 - acc: 0.9968\n",
      "Epoch 31/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0096 - acc: 0.9968\n",
      "Epoch 32/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 33/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0080 - acc: 0.9973\n",
      "Epoch 34/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 35/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0092 - acc: 0.9970\n",
      "Epoch 36/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0107 - acc: 0.9966\n",
      "Epoch 37/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0090 - acc: 0.9965\n",
      "Epoch 38/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0098 - acc: 0.9969\n",
      "Epoch 39/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0082 - acc: 0.9973\n",
      "Epoch 40/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 41/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0087 - acc: 0.9973\n",
      "Epoch 42/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0086 - acc: 0.9969\n",
      "Epoch 43/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0082 - acc: 0.9973\n",
      "Epoch 44/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0077 - acc: 0.9973\n",
      "Epoch 45/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0077 - acc: 0.9973\n",
      "Epoch 46/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0081 - acc: 0.9973\n",
      "Epoch 47/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0070 - acc: 0.9974\n",
      "Epoch 48/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0080 - acc: 0.9973\n",
      "Epoch 49/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 50/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0078 - acc: 0.9975\n",
      "Epoch 51/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 52/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0082 - acc: 0.9975\n",
      "Epoch 53/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0072 - acc: 0.9979\n",
      "Epoch 54/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0065 - acc: 0.9978\n",
      "Epoch 55/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 56/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 57/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 58/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 59/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0072 - acc: 0.9981\n",
      "Epoch 60/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0061 - acc: 0.9980\n",
      "5105/5105 [==============================] - 1s 102us/step\n",
      "!!!!!\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45947/45947 [==============================] - 2s 38us/step - loss: 0.5513 - acc: 0.6900\n",
      "Epoch 2/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.3473 - acc: 0.9067\n",
      "Epoch 3/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.2181 - acc: 0.9588\n",
      "Epoch 4/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.1410 - acc: 0.9788\n",
      "Epoch 5/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0847 - acc: 0.9877\n",
      "Epoch 6/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0562 - acc: 0.9911\n",
      "Epoch 7/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0417 - acc: 0.9928\n",
      "Epoch 8/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0323 - acc: 0.9928\n",
      "Epoch 9/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0247 - acc: 0.9946\n",
      "Epoch 10/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0189 - acc: 0.9955\n",
      "Epoch 11/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0207 - acc: 0.9948\n",
      "Epoch 12/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0170 - acc: 0.9957\n",
      "Epoch 13/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0162 - acc: 0.9953\n",
      "Epoch 14/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0127 - acc: 0.9969\n",
      "Epoch 15/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0147 - acc: 0.9956: 0s - loss: 0.0114 - acc: 0.99 - ETA: 0s - loss: 0.0130 -\n",
      "Epoch 16/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0148 - acc: 0.9958\n",
      "Epoch 17/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0134 - acc: 0.9959\n",
      "Epoch 18/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0116 - acc: 0.9965\n",
      "Epoch 19/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0111 - acc: 0.9965\n",
      "Epoch 20/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 21/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0111 - acc: 0.9965\n",
      "Epoch 22/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0115 - acc: 0.9966\n",
      "Epoch 23/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0102 - acc: 0.9968\n",
      "Epoch 24/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0113 - acc: 0.9967\n",
      "Epoch 25/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0087 - acc: 0.9974\n",
      "Epoch 26/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 27/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0111 - acc: 0.9964\n",
      "Epoch 28/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 29/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0098 - acc: 0.9967\n",
      "Epoch 30/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 31/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0089 - acc: 0.9971\n",
      "Epoch 32/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0082 - acc: 0.9975\n",
      "Epoch 33/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 34/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0076 - acc: 0.9974\n",
      "Epoch 35/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0081 - acc: 0.9973\n",
      "Epoch 36/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 37/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0085 - acc: 0.9977\n",
      "Epoch 38/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0099 - acc: 0.9967\n",
      "Epoch 39/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0108 - acc: 0.9971\n",
      "Epoch 40/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0073 - acc: 0.9975\n",
      "Epoch 41/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0078 - acc: 0.9973\n",
      "Epoch 42/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0077 - acc: 0.9975\n",
      "Epoch 43/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 44/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 45/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0083 - acc: 0.9973\n",
      "Epoch 46/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0073 - acc: 0.9976\n",
      "Epoch 47/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0084 - acc: 0.9976\n",
      "Epoch 48/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0072 - acc: 0.9978\n",
      "Epoch 49/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0088 - acc: 0.9975\n",
      "Epoch 50/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0083 - acc: 0.9970\n",
      "Epoch 51/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0061 - acc: 0.9982\n",
      "Epoch 52/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0085 - acc: 0.9973\n",
      "Epoch 53/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0086 - acc: 0.9971\n",
      "Epoch 54/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0075 - acc: 0.9975\n",
      "Epoch 55/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0069 - acc: 0.9975\n",
      "Epoch 56/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0078 - acc: 0.9973\n",
      "Epoch 57/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0067 - acc: 0.9977\n",
      "Epoch 58/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 59/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0065 - acc: 0.9977\n",
      "Epoch 60/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0058 - acc: 0.9983\n",
      "5105/5105 [==============================] - 1s 99us/step\n",
      "!!!!!\n",
      "Epoch 1/60\n",
      "45947/45947 [==============================] - 2s 37us/step - loss: 0.6684 - acc: 0.5784\n",
      "Epoch 2/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.4350 - acc: 0.8633\n",
      "Epoch 3/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.2649 - acc: 0.9563\n",
      "Epoch 4/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.1605 - acc: 0.9709\n",
      "Epoch 5/60\n",
      "45947/45947 [==============================] - 1s 15us/step - loss: 0.0947 - acc: 0.9857\n",
      "Epoch 6/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0588 - acc: 0.9902\n",
      "Epoch 7/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0382 - acc: 0.9928\n",
      "Epoch 8/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0262 - acc: 0.9942\n",
      "Epoch 9/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0211 - acc: 0.9952\n",
      "Epoch 10/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0185 - acc: 0.9955\n",
      "Epoch 11/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0171 - acc: 0.9957\n",
      "Epoch 12/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0154 - acc: 0.9951\n",
      "Epoch 13/60\n",
      "45947/45947 [==============================] - 1s 16us/step - loss: 0.0170 - acc: 0.9949\n",
      "Epoch 14/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0145 - acc: 0.9954\n",
      "Epoch 15/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0128 - acc: 0.9962\n",
      "Epoch 16/60\n",
      "45947/45947 [==============================] - 1s 17us/step - loss: 0.0121 - acc: 0.9962\n",
      "Epoch 17/60\n",
      "45947/45947 [==============================] - 1s 18us/step - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 18/60\n",
      "45947/45947 [==============================] - 1s 18us/step - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 19/60\n",
      "45947/45947 [==============================] - 1s 18us/step - loss: 0.0130 - acc: 0.9955\n",
      "Epoch 20/60\n",
      "45947/45947 [==============================] - 1s 19us/step - loss: 0.0110 - acc: 0.9965\n",
      "Epoch 21/60\n",
      "45947/45947 [==============================] - 1s 18us/step - loss: 0.0107 - acc: 0.9968\n",
      "Epoch 22/60\n",
      "45947/45947 [==============================] - 1s 18us/step - loss: 0.0105 - acc: 0.9966\n",
      "Epoch 23/60\n",
      "45947/45947 [==============================] - 1s 19us/step - loss: 0.0085 - acc: 0.9971\n",
      "Epoch 24/60\n",
      "45947/45947 [==============================] - 1s 19us/step - loss: 0.0110 - acc: 0.9964\n",
      "Epoch 25/60\n",
      "45947/45947 [==============================] - 1s 19us/step - loss: 0.0111 - acc: 0.9959\n",
      "Epoch 26/60\n",
      "45947/45947 [==============================] - 1s 19us/step - loss: 0.0101 - acc: 0.9964\n",
      "Epoch 27/60\n",
      "45947/45947 [==============================] - 1s 20us/step - loss: 0.0083 - acc: 0.9971\n",
      "Epoch 28/60\n",
      "45947/45947 [==============================] - 1s 21us/step - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 29/60\n",
      "45947/45947 [==============================] - 1s 21us/step - loss: 0.0095 - acc: 0.9975\n",
      "Epoch 30/60\n",
      "45947/45947 [==============================] - 1s 20us/step - loss: 0.0091 - acc: 0.9967\n",
      "Epoch 31/60\n",
      "45947/45947 [==============================] - 1s 21us/step - loss: 0.0115 - acc: 0.9956\n",
      "Epoch 32/60\n",
      "45947/45947 [==============================] - 1s 22us/step - loss: 0.0084 - acc: 0.9970\n",
      "Epoch 33/60\n",
      "45947/45947 [==============================] - 1s 22us/step - loss: 0.0101 - acc: 0.9965\n",
      "Epoch 34/60\n",
      "45947/45947 [==============================] - 1s 22us/step - loss: 0.0070 - acc: 0.9974\n",
      "Epoch 35/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0069 - acc: 0.9976\n",
      "Epoch 36/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0096 - acc: 0.9964\n",
      "Epoch 37/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0080 - acc: 0.9970\n",
      "Epoch 38/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 39/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 40/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0088 - acc: 0.9970\n",
      "Epoch 41/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0091 - acc: 0.9973\n",
      "Epoch 42/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0088 - acc: 0.9968\n",
      "Epoch 43/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 44/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0068 - acc: 0.9977\n",
      "Epoch 45/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0081 - acc: 0.9971\n",
      "Epoch 46/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0074 - acc: 0.9975\n",
      "Epoch 47/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 48/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0071 - acc: 0.9974\n",
      "Epoch 49/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0083 - acc: 0.9980\n",
      "Epoch 50/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0067 - acc: 0.9979\n",
      "Epoch 51/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0076 - acc: 0.9977\n",
      "Epoch 52/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0082 - acc: 0.9972 ETA: 1s - loss: 0\n",
      "Epoch 53/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0066 - acc: 0.9979\n",
      "Epoch 54/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0075 - acc: 0.9976\n",
      "Epoch 55/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 56/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0080 - acc: 0.9975\n",
      "Epoch 57/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0056 - acc: 0.9982\n",
      "Epoch 58/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0060 - acc: 0.9982\n",
      "Epoch 59/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0062 - acc: 0.9978\n",
      "Epoch 60/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0075 - acc: 0.9975\n",
      "5105/5105 [==============================] - 1s 167us/step\n",
      "!!!!!\n",
      "Epoch 1/60\n",
      "45947/45947 [==============================] - 3s 61us/step - loss: 0.6110 - acc: 0.6482\n",
      "Epoch 2/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.4648 - acc: 0.7880\n",
      "Epoch 3/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.3184 - acc: 0.9160\n",
      "Epoch 4/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.2414 - acc: 0.9464\n",
      "Epoch 5/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.1847 - acc: 0.9690\n",
      "Epoch 6/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.1319 - acc: 0.9815: 1s - loss: \n",
      "Epoch 7/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0946 - acc: 0.9883\n",
      "Epoch 8/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0649 - acc: 0.9921\n",
      "Epoch 9/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0464 - acc: 0.9929\n",
      "Epoch 10/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0334 - acc: 0.9943\n",
      "Epoch 11/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0251 - acc: 0.9953\n",
      "Epoch 12/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0183 - acc: 0.9961\n",
      "Epoch 13/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0163 - acc: 0.9955\n",
      "Epoch 14/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0146 - acc: 0.9963\n",
      "Epoch 15/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0128 - acc: 0.9961\n",
      "Epoch 16/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0132 - acc: 0.9964\n",
      "Epoch 17/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 18/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 19/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0119 - acc: 0.9960\n",
      "Epoch 20/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0097 - acc: 0.9971\n",
      "Epoch 21/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0096 - acc: 0.9967\n",
      "Epoch 22/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0091 - acc: 0.9972\n",
      "Epoch 23/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0098 - acc: 0.9966\n",
      "Epoch 24/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0089 - acc: 0.9967\n",
      "Epoch 25/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0106 - acc: 0.9966\n",
      "Epoch 26/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 27/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0095 - acc: 0.9968\n",
      "Epoch 28/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 29/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 30/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 31/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0090 - acc: 0.9977\n",
      "Epoch 32/60\n",
      "45947/45947 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.997 - 1s 31us/step - loss: 0.0082 - acc: 0.9976\n",
      "Epoch 33/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0075 - acc: 0.9980\n",
      "Epoch 34/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 35/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0082 - acc: 0.9975\n",
      "Epoch 36/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0072 - acc: 0.9980\n",
      "Epoch 37/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0077 - acc: 0.9976\n",
      "Epoch 38/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0077 - acc: 0.9979\n",
      "Epoch 39/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0077 - acc: 0.9976\n",
      "Epoch 40/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0078 - acc: 0.9978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0078 - acc: 0.9979\n",
      "Epoch 42/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0075 - acc: 0.9975\n",
      "Epoch 43/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0072 - acc: 0.9981\n",
      "Epoch 44/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0074 - acc: 0.9978\n",
      "Epoch 45/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 46/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0078 - acc: 0.9981\n",
      "Epoch 47/60\n",
      "45947/45947 [==============================] - 1s 31us/step - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 48/60\n",
      "45947/45947 [==============================] - 1s 30us/step - loss: 0.0082 - acc: 0.9980\n",
      "Epoch 49/60\n",
      "45947/45947 [==============================] - 1s 30us/step - loss: 0.0057 - acc: 0.9985\n",
      "Epoch 50/60\n",
      "45947/45947 [==============================] - 1s 30us/step - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 51/60\n",
      "45947/45947 [==============================] - 1s 30us/step - loss: 0.0082 - acc: 0.9978\n",
      "Epoch 52/60\n",
      "45947/45947 [==============================] - 1s 30us/step - loss: 0.0072 - acc: 0.9978\n",
      "Epoch 53/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 54/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0073 - acc: 0.9975\n",
      "Epoch 55/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 56/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0071 - acc: 0.9979\n",
      "Epoch 57/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0063 - acc: 0.9983\n",
      "Epoch 58/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0062 - acc: 0.9981\n",
      "Epoch 59/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0079 - acc: 0.9979\n",
      "Epoch 60/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0074 - acc: 0.9977\n",
      "5105/5105 [==============================] - 1s 166us/step\n",
      "!!!!!\n",
      "Epoch 1/60\n",
      "45947/45947 [==============================] - 3s 57us/step - loss: 0.4613 - acc: 0.7314\n",
      "Epoch 2/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.2840 - acc: 0.9148\n",
      "Epoch 3/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.1758 - acc: 0.9775\n",
      "Epoch 4/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.1078 - acc: 0.9860\n",
      "Epoch 5/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0701 - acc: 0.9877\n",
      "Epoch 6/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0517 - acc: 0.9899\n",
      "Epoch 7/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0406 - acc: 0.9905\n",
      "Epoch 8/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0329 - acc: 0.9918\n",
      "Epoch 9/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0277 - acc: 0.9928\n",
      "Epoch 10/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0225 - acc: 0.9937\n",
      "Epoch 11/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 12/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0194 - acc: 0.9938\n",
      "Epoch 13/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0203 - acc: 0.9930\n",
      "Epoch 14/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0183 - acc: 0.9944\n",
      "Epoch 15/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0180 - acc: 0.9942\n",
      "Epoch 16/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0207 - acc: 0.9936\n",
      "Epoch 17/60\n",
      "45947/45947 [==============================] - 1s 29us/step - loss: 0.0172 - acc: 0.9939\n",
      "Epoch 18/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0163 - acc: 0.9949\n",
      "Epoch 19/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0164 - acc: 0.9941\n",
      "Epoch 20/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0143 - acc: 0.9946\n",
      "Epoch 21/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0130 - acc: 0.9963\n",
      "Epoch 22/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0145 - acc: 0.9951\n",
      "Epoch 23/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0153 - acc: 0.9948\n",
      "Epoch 24/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0119 - acc: 0.9965\n",
      "Epoch 25/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 26/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0106 - acc: 0.9962\n",
      "Epoch 27/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0118 - acc: 0.9961\n",
      "Epoch 28/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0120 - acc: 0.9956\n",
      "Epoch 29/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0127 - acc: 0.9956\n",
      "Epoch 30/60\n",
      "45947/45947 [==============================] - 1s 30us/step - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 31/60\n",
      "45947/45947 [==============================] - 1s 29us/step - loss: 0.0093 - acc: 0.9974\n",
      "Epoch 32/60\n",
      "45947/45947 [==============================] - 1s 30us/step - loss: 0.0116 - acc: 0.9961\n",
      "Epoch 33/60\n",
      "45947/45947 [==============================] - 1s 29us/step - loss: 0.0118 - acc: 0.9961\n",
      "Epoch 34/60\n",
      "45947/45947 [==============================] - 1s 29us/step - loss: 0.0098 - acc: 0.9966\n",
      "Epoch 35/60\n",
      "45947/45947 [==============================] - 1s 29us/step - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 36/60\n",
      "45947/45947 [==============================] - 1s 29us/step - loss: 0.0108 - acc: 0.9968\n",
      "Epoch 37/60\n",
      "45947/45947 [==============================] - 1s 29us/step - loss: 0.0130 - acc: 0.9957\n",
      "Epoch 38/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0104 - acc: 0.9964\n",
      "Epoch 39/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0104 - acc: 0.9966\n",
      "Epoch 40/60\n",
      "45947/45947 [==============================] - 1s 30us/step - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 41/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0126 - acc: 0.9948\n",
      "Epoch 42/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0089 - acc: 0.9973\n",
      "Epoch 43/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 44/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0094 - acc: 0.9966\n",
      "Epoch 45/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 46/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 47/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0092 - acc: 0.9966\n",
      "Epoch 48/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0097 - acc: 0.9964\n",
      "Epoch 49/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 50/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0092 - acc: 0.9968\n",
      "Epoch 51/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 52/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0080 - acc: 0.9973\n",
      "Epoch 53/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 54/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0090 - acc: 0.9968\n",
      "Epoch 55/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0090 - acc: 0.9970\n",
      "Epoch 56/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0119 - acc: 0.9969\n",
      "Epoch 57/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0090 - acc: 0.9973\n",
      "Epoch 58/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0084 - acc: 0.9971\n",
      "Epoch 59/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0068 - acc: 0.9976\n",
      "Epoch 60/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0073 - acc: 0.9978\n",
      "5105/5105 [==============================] - 1s 172us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!\n",
      "Epoch 1/60\n",
      "45947/45947 [==============================] - 3s 60us/step - loss: 0.5490 - acc: 0.6944\n",
      "Epoch 2/60\n",
      "45947/45947 [==============================] - 1s 22us/step - loss: 0.3962 - acc: 0.8600\n",
      "Epoch 3/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.3392 - acc: 0.8699\n",
      "Epoch 4/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.2991 - acc: 0.8827\n",
      "Epoch 5/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.2660 - acc: 0.9038\n",
      "Epoch 6/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.2313 - acc: 0.9243\n",
      "Epoch 7/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.1819 - acc: 0.9501\n",
      "Epoch 8/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.1283 - acc: 0.9763\n",
      "Epoch 9/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0673 - acc: 0.9893\n",
      "Epoch 10/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0417 - acc: 0.9929\n",
      "Epoch 11/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0314 - acc: 0.9937\n",
      "Epoch 12/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0241 - acc: 0.9950\n",
      "Epoch 13/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0211 - acc: 0.9947\n",
      "Epoch 14/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0176 - acc: 0.9950\n",
      "Epoch 15/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0170 - acc: 0.9952\n",
      "Epoch 16/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0139 - acc: 0.9961\n",
      "Epoch 17/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0138 - acc: 0.9956\n",
      "Epoch 18/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0173 - acc: 0.9937\n",
      "Epoch 19/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0148 - acc: 0.9950\n",
      "Epoch 20/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0133 - acc: 0.9954\n",
      "Epoch 21/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 22/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0118 - acc: 0.9971\n",
      "Epoch 23/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 24/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0098 - acc: 0.9972\n",
      "Epoch 25/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0092 - acc: 0.9975\n",
      "Epoch 26/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 27/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0107 - acc: 0.9965\n",
      "Epoch 28/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0106 - acc: 0.9967\n",
      "Epoch 29/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 30/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0109 - acc: 0.9960\n",
      "Epoch 31/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0085 - acc: 0.9975\n",
      "Epoch 32/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 33/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0095 - acc: 0.9958\n",
      "Epoch 34/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0082 - acc: 0.9978\n",
      "Epoch 35/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0103 - acc: 0.9962\n",
      "Epoch 36/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0085 - acc: 0.9975\n",
      "Epoch 37/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 38/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0094 - acc: 0.9971\n",
      "Epoch 39/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0093 - acc: 0.9966\n",
      "Epoch 40/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0092 - acc: 0.9973\n",
      "Epoch 41/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 42/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0084 - acc: 0.9971\n",
      "Epoch 43/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 44/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0077 - acc: 0.9976\n",
      "Epoch 45/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0091 - acc: 0.9965\n",
      "Epoch 46/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0104 - acc: 0.9968\n",
      "Epoch 47/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 48/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0068 - acc: 0.9981\n",
      "Epoch 49/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0079 - acc: 0.9979\n",
      "Epoch 50/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 51/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 52/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0075 - acc: 0.9972\n",
      "Epoch 53/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0069 - acc: 0.9980\n",
      "Epoch 54/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0092 - acc: 0.9973\n",
      "Epoch 55/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 56/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0087 - acc: 0.9972\n",
      "Epoch 57/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0071 - acc: 0.9975\n",
      "Epoch 58/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0083 - acc: 0.9974\n",
      "Epoch 59/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0087 - acc: 0.9960\n",
      "Epoch 60/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0065 - acc: 0.9983\n",
      "5105/5105 [==============================] - 1s 171us/step\n",
      "!!!!!\n",
      "Epoch 1/60\n",
      "45947/45947 [==============================] - 3s 58us/step - loss: 0.5763 - acc: 0.6582\n",
      "Epoch 2/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.4230 - acc: 0.8220\n",
      "Epoch 3/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.3277 - acc: 0.8690\n",
      "Epoch 4/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.2045 - acc: 0.9554\n",
      "Epoch 5/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0929 - acc: 0.9885\n",
      "Epoch 6/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0552 - acc: 0.9918\n",
      "Epoch 7/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0390 - acc: 0.9933\n",
      "Epoch 8/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0307 - acc: 0.9930\n",
      "Epoch 9/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0262 - acc: 0.9928\n",
      "Epoch 10/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0218 - acc: 0.9948\n",
      "Epoch 11/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0207 - acc: 0.9942\n",
      "Epoch 12/60\n",
      "45947/45947 [==============================] - 1s 23us/step - loss: 0.0185 - acc: 0.9945\n",
      "Epoch 13/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0171 - acc: 0.9953\n",
      "Epoch 14/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0171 - acc: 0.9947\n",
      "Epoch 15/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0161 - acc: 0.9950\n",
      "Epoch 16/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0150 - acc: 0.9951\n",
      "Epoch 17/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0148 - acc: 0.9943\n",
      "Epoch 18/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0140 - acc: 0.9957\n",
      "Epoch 19/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0137 - acc: 0.9953\n",
      "Epoch 20/60\n",
      "45947/45947 [==============================] - 1s 29us/step - loss: 0.0110 - acc: 0.9958\n",
      "Epoch 21/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0136 - acc: 0.9950\n",
      "Epoch 22/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0112 - acc: 0.9960\n",
      "Epoch 23/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0121 - acc: 0.9959\n",
      "Epoch 24/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0116 - acc: 0.9959\n",
      "Epoch 25/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0130 - acc: 0.9955\n",
      "Epoch 26/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0106 - acc: 0.9969\n",
      "Epoch 27/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0092 - acc: 0.9971\n",
      "Epoch 28/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 29/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0116 - acc: 0.9961\n",
      "Epoch 30/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 31/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0117 - acc: 0.9960\n",
      "Epoch 32/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0091 - acc: 0.9964\n",
      "Epoch 33/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0091 - acc: 0.9967\n",
      "Epoch 34/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0083 - acc: 0.9972\n",
      "Epoch 35/60\n",
      "45947/45947 [==============================] - 1s 28us/step - loss: 0.0128 - acc: 0.9952\n",
      "Epoch 36/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0098 - acc: 0.9971\n",
      "Epoch 37/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 38/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0093 - acc: 0.9976\n",
      "Epoch 39/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 40/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0075 - acc: 0.9974\n",
      "Epoch 41/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0095 - acc: 0.9967\n",
      "Epoch 42/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0073 - acc: 0.9980\n",
      "Epoch 43/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0065 - acc: 0.9982\n",
      "Epoch 44/60\n",
      "45947/45947 [==============================] - 1s 27us/step - loss: 0.0073 - acc: 0.9974ETA: 1s - loss:\n",
      "Epoch 45/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0074 - acc: 0.9975\n",
      "Epoch 46/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0074 - acc: 0.9979\n",
      "Epoch 47/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0076 - acc: 0.9970\n",
      "Epoch 48/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 49/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0061 - acc: 0.9979\n",
      "Epoch 50/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0092 - acc: 0.9973\n",
      "Epoch 51/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 52/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 53/60\n",
      "45947/45947 [==============================] - 1s 24us/step - loss: 0.0072 - acc: 0.9980\n",
      "Epoch 54/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 55/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0086 - acc: 0.9974\n",
      "Epoch 56/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0074 - acc: 0.9974\n",
      "Epoch 57/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0064 - acc: 0.9978\n",
      "Epoch 58/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0060 - acc: 0.9982\n",
      "Epoch 59/60\n",
      "45947/45947 [==============================] - 1s 26us/step - loss: 0.0055 - acc: 0.9982\n",
      "Epoch 60/60\n",
      "45947/45947 [==============================] - 1s 25us/step - loss: 0.0068 - acc: 0.9978\n",
      "5105/5105 [==============================] - 1s 180us/step\n",
      "!!!!!\n"
     ]
    }
   ],
   "source": [
    "NNR10=[]\n",
    "precisionR10=[]\n",
    "recallR10=[]\n",
    "TruePositive10 =[]\n",
    "FalsePositive10 =[]\n",
    "for train, test in kf_total:\n",
    "    TrainX=pd.DataFrame(LassoInput[list(train),:])\n",
    "    Trainy=pd.DataFrame(output[list(train)])\n",
    "    TestX=pd.DataFrame(LassoInput[list(test),:])\n",
    "    Testy=pd.DataFrame(output[list(test)])\n",
    "    \n",
    "    model,score, precision, recall, TN, FP, FN, TP, yPredict=NNModelFunction(np.array(TrainX), np.array(Trainy)\n",
    "                    , \n",
    "                    np.array(TestX),np.array(Testy)\n",
    "                    ,len(commonLassoFeatures))\n",
    "    NNR10.append(score)\n",
    "    precisionR10.append(precision)\n",
    "    recallR10.append(recall)\n",
    "    TruePositive10.append(TP)\n",
    "    FalsePositive10.append(FP)\n",
    "    print(\"!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.99451519654\n",
      "Precision\n",
      "0.992647134519\n",
      "ReCall\n",
      "0.999353715857\n",
      "TruePositive\n",
      "3254.2\n",
      "False Posisive\n",
      "25.9\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:\")\n",
    "print(np.mean(NNR10))\n",
    "print(\"Precision\")\n",
    "print(np.mean(precisionR10))\n",
    "print(\"ReCall\")\n",
    "print(np.mean(recallR10))\n",
    "print(\"TruePositive\")\n",
    "print(np.mean(TruePositive10) )\n",
    "print(\"False Posisive\")\n",
    "print(np.mean(FalsePositive10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "45946/45946 [==============================] - 5s 118us/step - loss: 0.4596 - acc: 0.7584\n",
      "Epoch 2/32\n",
      "45946/45946 [==============================] - 3s 63us/step - loss: 0.3441 - acc: 0.8568\n",
      "Epoch 3/32\n",
      "45946/45946 [==============================] - 3s 64us/step - loss: 0.2889 - acc: 0.8983\n",
      "Epoch 4/32\n",
      "45946/45946 [==============================] - 3s 63us/step - loss: 0.2018 - acc: 0.9351\n",
      "Epoch 5/32\n",
      "45946/45946 [==============================] - 3s 66us/step - loss: 0.1733 - acc: 0.9529\n",
      "Epoch 6/32\n",
      "45946/45946 [==============================] - 3s 70us/step - loss: 0.1540 - acc: 0.9634\n",
      "Epoch 7/32\n",
      "45946/45946 [==============================] - 3s 71us/step - loss: 0.1094 - acc: 0.9679\n",
      "Epoch 8/32\n",
      "45946/45946 [==============================] - 3s 74us/step - loss: 0.1070 - acc: 0.9718\n",
      "Epoch 9/32\n",
      "45946/45946 [==============================] - 3s 72us/step - loss: 0.1154 - acc: 0.9734\n",
      "Epoch 10/32\n",
      "45946/45946 [==============================] - 3s 72us/step - loss: 0.0920 - acc: 0.9757\n",
      "Epoch 11/32\n",
      "45946/45946 [==============================] - 3s 73us/step - loss: 0.0828 - acc: 0.9808\n",
      "Epoch 12/32\n",
      "45946/45946 [==============================] - 3s 74us/step - loss: 0.1406 - acc: 0.9779\n",
      "Epoch 13/32\n",
      "45946/45946 [==============================] - 3s 72us/step - loss: 0.1019 - acc: 0.9794\n",
      "Epoch 14/32\n",
      "45946/45946 [==============================] - 3s 73us/step - loss: 0.1039 - acc: 0.9803\n",
      "Epoch 15/32\n",
      "45946/45946 [==============================] - 3s 71us/step - loss: 0.0720 - acc: 0.9844\n",
      "Epoch 16/32\n",
      "45946/45946 [==============================] - 3s 68us/step - loss: 0.0715 - acc: 0.9844\n",
      "Epoch 17/32\n",
      "45946/45946 [==============================] - 3s 69us/step - loss: 0.1407 - acc: 0.9826\n",
      "Epoch 18/32\n",
      "45946/45946 [==============================] - 3s 68us/step - loss: 0.1362 - acc: 0.9782\n",
      "Epoch 19/32\n",
      "45946/45946 [==============================] - 3s 68us/step - loss: 0.1047 - acc: 0.9835\n",
      "Epoch 20/32\n",
      "45946/45946 [==============================] - 3s 69us/step - loss: 0.1873 - acc: 0.9767\n",
      "Epoch 21/32\n",
      "45946/45946 [==============================] - 3s 70us/step - loss: 0.0906 - acc: 0.9858\n",
      "Epoch 22/32\n",
      "45946/45946 [==============================] - 3s 69us/step - loss: 0.0849 - acc: 0.9871\n",
      "Epoch 23/32\n",
      "45946/45946 [==============================] - 3s 69us/step - loss: 0.1130 - acc: 0.9859\n",
      "Epoch 24/32\n",
      "45946/45946 [==============================] - 3s 72us/step - loss: 0.0746 - acc: 0.9860\n",
      "Epoch 25/32\n",
      "45946/45946 [==============================] - 3s 75us/step - loss: 0.0873 - acc: 0.9874\n",
      "Epoch 26/32\n",
      "45946/45946 [==============================] - 3s 75us/step - loss: 0.1097 - acc: 0.9845\n",
      "Epoch 27/32\n",
      "45946/45946 [==============================] - 3s 76us/step - loss: 0.2907 - acc: 0.9727\n",
      "Epoch 28/32\n",
      "45946/45946 [==============================] - 3s 75us/step - loss: 0.0659 - acc: 0.9877\n",
      "Epoch 29/32\n",
      "45946/45946 [==============================] - 3s 74us/step - loss: 0.0760 - acc: 0.9901\n",
      "Epoch 30/32\n",
      "45946/45946 [==============================] - 3s 75us/step - loss: 0.1522 - acc: 0.9863\n",
      "Epoch 31/32\n",
      "45946/45946 [==============================] - 3s 69us/step - loss: 0.0782 - acc: 0.9894\n",
      "Epoch 32/32\n",
      "45946/45946 [==============================] - 3s 68us/step - loss: 0.0736 - acc: 0.9907\n",
      "5106/5106 [==============================] - 1s 153us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45946/45946 [==============================] - 5s 116us/step - loss: 0.4733 - acc: 0.7455\n",
      "Epoch 2/32\n",
      "45946/45946 [==============================] - 3s 63us/step - loss: 0.3852 - acc: 0.8543\n",
      "Epoch 3/32\n",
      "45946/45946 [==============================] - 3s 63us/step - loss: 0.2341 - acc: 0.8982\n",
      "Epoch 4/32\n",
      "45946/45946 [==============================] - 3s 67us/step - loss: 0.1838 - acc: 0.9270\n",
      "Epoch 5/32\n",
      "45946/45946 [==============================] - 3s 70us/step - loss: 0.1477 - acc: 0.9514\n",
      "Epoch 6/32\n",
      "45946/45946 [==============================] - 3s 76us/step - loss: 0.1180 - acc: 0.9652\n",
      "Epoch 7/32\n",
      "45946/45946 [==============================] - 4s 80us/step - loss: 0.0980 - acc: 0.9695\n",
      "Epoch 8/32\n",
      "45946/45946 [==============================] - 4s 77us/step - loss: 0.0888 - acc: 0.9749\n",
      "Epoch 9/32\n",
      "45946/45946 [==============================] - 4s 81us/step - loss: 0.0780 - acc: 0.9803\n",
      "Epoch 10/32\n",
      "45946/45946 [==============================] - 4s 80us/step - loss: 0.0880 - acc: 0.9795\n",
      "Epoch 11/32\n",
      "45946/45946 [==============================] - 4s 82us/step - loss: 0.1116 - acc: 0.9755\n",
      "Epoch 12/32\n",
      "45946/45946 [==============================] - 4s 84us/step - loss: 0.0832 - acc: 0.9834\n",
      "Epoch 13/32\n",
      "45946/45946 [==============================] - ETA: 0s - loss: 0.0949 - acc: 0.983 - 4s 82us/step - loss: 0.1024 - acc: 0.9821\n",
      "Epoch 14/32\n",
      "45946/45946 [==============================] - 4s 78us/step - loss: 0.1079 - acc: 0.9827\n",
      "Epoch 15/32\n",
      "45946/45946 [==============================] - 4s 77us/step - loss: 0.1101 - acc: 0.9807\n",
      "Epoch 16/32\n",
      "45946/45946 [==============================] - 4s 78us/step - loss: 0.0850 - acc: 0.9844\n",
      "Epoch 17/32\n",
      "45946/45946 [==============================] - 4s 80us/step - loss: 1.6663 - acc: 0.8892\n",
      "Epoch 18/32\n",
      "45946/45946 [==============================] - 3s 74us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 19/32\n",
      "45946/45946 [==============================] - 3s 71us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 20/32\n",
      "45946/45946 [==============================] - 3s 71us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 21/32\n",
      "45946/45946 [==============================] - 3s 73us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 22/32\n",
      "45946/45946 [==============================] - 4s 78us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 23/32\n",
      "45946/45946 [==============================] - 4s 77us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 24/32\n",
      "45946/45946 [==============================] - 4s 79us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 25/32\n",
      "45946/45946 [==============================] - 4s 77us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 26/32\n",
      "45946/45946 [==============================] - 4s 79us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 27/32\n",
      "45946/45946 [==============================] - 4s 78us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 28/32\n",
      "45946/45946 [==============================] - 4s 77us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 29/32\n",
      "45946/45946 [==============================] - 4s 77us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 30/32\n",
      "45946/45946 [==============================] - 3s 75us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 31/32\n",
      "45946/45946 [==============================] - 3s 71us/step - loss: 10.2796 - acc: 0.3622\n",
      "Epoch 32/32\n",
      "45946/45946 [==============================] - 3s 73us/step - loss: 10.2796 - acc: 0.3622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5106/5106 [==============================] - 1s 160us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45947/45947 [==============================] - 5s 118us/step - loss: 0.5773 - acc: 0.7401\n",
      "Epoch 2/32\n",
      "45947/45947 [==============================] - 3s 61us/step - loss: 0.3327 - acc: 0.8432\n",
      "Epoch 3/32\n",
      "45947/45947 [==============================] - 3s 64us/step - loss: 0.2656 - acc: 0.8877\n",
      "Epoch 4/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.2110 - acc: 0.9139\n",
      "Epoch 5/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.1802 - acc: 0.9377\n",
      "Epoch 6/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.1399 - acc: 0.9526\n",
      "Epoch 7/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.1368 - acc: 0.9637\n",
      "Epoch 8/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.1067 - acc: 0.9713\n",
      "Epoch 9/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.1036 - acc: 0.9718\n",
      "Epoch 10/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.1094 - acc: 0.9761\n",
      "Epoch 11/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0854 - acc: 0.9783\n",
      "Epoch 12/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.1240 - acc: 0.9760\n",
      "Epoch 13/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.0929 - acc: 0.9812\n",
      "Epoch 14/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.1166 - acc: 0.9798\n",
      "Epoch 15/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0927 - acc: 0.9852\n",
      "Epoch 16/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0950 - acc: 0.9829\n",
      "Epoch 17/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.1010 - acc: 0.9803\n",
      "Epoch 18/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.0927 - acc: 0.9827\n",
      "Epoch 19/32\n",
      "45947/45947 [==============================] - 3s 67us/step - loss: 0.0645 - acc: 0.9861\n",
      "Epoch 20/32\n",
      "45947/45947 [==============================] - 3s 69us/step - loss: 0.1187 - acc: 0.9818\n",
      "Epoch 21/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.0772 - acc: 0.9850\n",
      "Epoch 22/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.1068 - acc: 0.9879\n",
      "Epoch 23/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.1373 - acc: 0.9812\n",
      "Epoch 24/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.0953 - acc: 0.9853\n",
      "Epoch 25/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.1360 - acc: 0.9849\n",
      "Epoch 26/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.3947 - acc: 0.9713\n",
      "Epoch 27/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.0982 - acc: 0.9817\n",
      "Epoch 28/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.1104 - acc: 0.9874\n",
      "Epoch 29/32\n",
      "45947/45947 [==============================] - 3s 72us/step - loss: 0.3628 - acc: 0.9741\n",
      "Epoch 30/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.0985 - acc: 0.9889\n",
      "Epoch 31/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.1380 - acc: 0.9855\n",
      "Epoch 32/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0753 - acc: 0.9869\n",
      "5105/5105 [==============================] - 1s 172us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45947/45947 [==============================] - 5s 117us/step - loss: 0.4717 - acc: 0.7727\n",
      "Epoch 2/32\n",
      "45947/45947 [==============================] - 3s 61us/step - loss: 0.2983 - acc: 0.8707\n",
      "Epoch 3/32\n",
      "45947/45947 [==============================] - 3s 61us/step - loss: 0.2171 - acc: 0.9099\n",
      "Epoch 4/32\n",
      "45947/45947 [==============================] - 3s 64us/step - loss: 0.1696 - acc: 0.9412\n",
      "Epoch 5/32\n",
      "45947/45947 [==============================] - 3s 66us/step - loss: 0.1413 - acc: 0.9528\n",
      "Epoch 6/32\n",
      "45947/45947 [==============================] - 3s 67us/step - loss: 0.1127 - acc: 0.9644\n",
      "Epoch 7/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 0.0952 - acc: 0.9737\n",
      "Epoch 8/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0910 - acc: 0.9766\n",
      "Epoch 9/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.1012 - acc: 0.9802\n",
      "Epoch 10/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0837 - acc: 0.9789\n",
      "Epoch 11/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0716 - acc: 0.9828\n",
      "Epoch 12/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0801 - acc: 0.9827\n",
      "Epoch 13/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0819 - acc: 0.9837\n",
      "Epoch 14/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1029 - acc: 0.9811\n",
      "Epoch 15/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.0850 - acc: 0.9844\n",
      "Epoch 16/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.1397 - acc: 0.9819\n",
      "Epoch 17/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1105 - acc: 0.9809\n",
      "Epoch 18/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.0995 - acc: 0.9826\n",
      "Epoch 19/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0642 - acc: 0.9883\n",
      "Epoch 20/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.0736 - acc: 0.9867\n",
      "Epoch 21/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0540 - acc: 0.9882\n",
      "Epoch 22/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1501 - acc: 0.9837\n",
      "Epoch 23/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1399 - acc: 0.9824\n",
      "Epoch 24/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.2270 - acc: 0.9771\n",
      "Epoch 25/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.0934 - acc: 0.9885\n",
      "Epoch 26/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.4104 - acc: 0.9658\n",
      "Epoch 27/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 5.7750 - acc: 0.6378\n",
      "Epoch 28/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 5.7750 - acc: 0.6378\n",
      "Epoch 29/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 5.7750 - acc: 0.6378\n",
      "Epoch 30/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 5.7750 - acc: 0.6378\n",
      "Epoch 31/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 5.7750 - acc: 0.6378\n",
      "Epoch 32/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 5.7750 - acc: 0.6378\n",
      "5105/5105 [==============================] - 1s 180us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45947/45947 [==============================] - 6s 123us/step - loss: 0.4820 - acc: 0.7514\n",
      "Epoch 2/32\n",
      "45947/45947 [==============================] - 3s 62us/step - loss: 0.3013 - acc: 0.8594\n",
      "Epoch 3/32\n",
      "45947/45947 [==============================] - 3s 65us/step - loss: 0.2498 - acc: 0.8994\n",
      "Epoch 4/32\n",
      "45947/45947 [==============================] - 3s 69us/step - loss: 0.2191 - acc: 0.9181\n",
      "Epoch 5/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 0.1772 - acc: 0.9404\n",
      "Epoch 6/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.1632 - acc: 0.9505\n",
      "Epoch 7/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1200 - acc: 0.9626\n",
      "Epoch 8/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.1263 - acc: 0.9697\n",
      "Epoch 9/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.0964 - acc: 0.9738\n",
      "Epoch 10/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.0893 - acc: 0.9744\n",
      "Epoch 11/32\n",
      "45947/45947 [==============================] - 4s 83us/step - loss: 0.0851 - acc: 0.9796\n",
      "Epoch 12/32\n",
      "45947/45947 [==============================] - 4s 83us/step - loss: 0.0843 - acc: 0.9806\n",
      "Epoch 13/32\n",
      "45947/45947 [==============================] - 4s 83us/step - loss: 0.0861 - acc: 0.9819\n",
      "Epoch 14/32\n",
      "45947/45947 [==============================] - 4s 83us/step - loss: 0.0634 - acc: 0.9838\n",
      "Epoch 15/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1277 - acc: 0.9811\n",
      "Epoch 16/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0692 - acc: 0.9850\n",
      "Epoch 17/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1401 - acc: 0.9805\n",
      "Epoch 18/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0751 - acc: 0.9873\n",
      "Epoch 19/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.0806 - acc: 0.9860\n",
      "Epoch 20/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0988 - acc: 0.9857\n",
      "Epoch 21/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.1097 - acc: 0.9862\n",
      "Epoch 22/32\n",
      "45947/45947 [==============================] - 3s 69us/step - loss: 0.1650 - acc: 0.9815\n",
      "Epoch 23/32\n",
      "45947/45947 [==============================] - 3s 67us/step - loss: 0.1107 - acc: 0.9797\n",
      "Epoch 24/32\n",
      "45947/45947 [==============================] - 3s 68us/step - loss: 0.1095 - acc: 0.9845\n",
      "Epoch 25/32\n",
      "45947/45947 [==============================] - 3s 68us/step - loss: 0.0757 - acc: 0.9896\n",
      "Epoch 26/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.0702 - acc: 0.9872\n",
      "Epoch 27/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0715 - acc: 0.9880\n",
      "Epoch 28/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0823 - acc: 0.9894\n",
      "Epoch 29/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0636 - acc: 0.9890\n",
      "Epoch 30/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.0488 - acc: 0.9911\n",
      "Epoch 31/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1532 - acc: 0.9840\n",
      "Epoch 32/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0468 - acc: 0.9919\n",
      "5105/5105 [==============================] - 1s 202us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45947/45947 [==============================] - 6s 130us/step - loss: 0.6735 - acc: 0.7265\n",
      "Epoch 2/32\n",
      "45947/45947 [==============================] - 3s 65us/step - loss: 0.3843 - acc: 0.8307\n",
      "Epoch 3/32\n",
      "45947/45947 [==============================] - 3s 64us/step - loss: 0.3414 - acc: 0.8642\n",
      "Epoch 4/32\n",
      "45947/45947 [==============================] - 3s 66us/step - loss: 0.2939 - acc: 0.8822\n",
      "Epoch 5/32\n",
      "45947/45947 [==============================] - 3s 74us/step - loss: 0.2542 - acc: 0.9064\n",
      "Epoch 6/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.2346 - acc: 0.9176\n",
      "Epoch 7/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.2034 - acc: 0.9365\n",
      "Epoch 8/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1922 - acc: 0.9509\n",
      "Epoch 9/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.1436 - acc: 0.9595\n",
      "Epoch 10/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.1186 - acc: 0.9670\n",
      "Epoch 11/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1250 - acc: 0.9719\n",
      "Epoch 12/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1160 - acc: 0.9714\n",
      "Epoch 13/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1254 - acc: 0.9793\n",
      "Epoch 14/32\n",
      "45947/45947 [==============================] - 4s 86us/step - loss: 0.0917 - acc: 0.9790\n",
      "Epoch 15/32\n",
      "45947/45947 [==============================] - 4s 86us/step - loss: 0.0945 - acc: 0.9797\n",
      "Epoch 16/32\n",
      "45947/45947 [==============================] - 4s 85us/step - loss: 0.1036 - acc: 0.9802\n",
      "Epoch 17/32\n",
      "45947/45947 [==============================] - 4s 84us/step - loss: 0.1333 - acc: 0.9821\n",
      "Epoch 18/32\n",
      "45947/45947 [==============================] - 4s 85us/step - loss: 0.1425 - acc: 0.9815\n",
      "Epoch 19/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.2301 - acc: 0.9684\n",
      "Epoch 20/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.1373 - acc: 0.9835\n",
      "Epoch 21/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.0828 - acc: 0.9861\n",
      "Epoch 22/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1088 - acc: 0.9834\n",
      "Epoch 23/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.5994 - acc: 0.9552\n",
      "Epoch 24/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.7934 - acc: 0.9423\n",
      "Epoch 25/32\n",
      "45947/45947 [==============================] - 3s 69us/step - loss: 0.3686 - acc: 0.9692\n",
      "Epoch 26/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 0.1133 - acc: 0.9868\n",
      "Epoch 27/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 0.0769 - acc: 0.9877\n",
      "Epoch 28/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 0.1162 - acc: 0.9859\n",
      "Epoch 29/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.3753 - acc: 0.9559\n",
      "Epoch 30/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.2288 - acc: 0.9804\n",
      "Epoch 31/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.0796 - acc: 0.9881\n",
      "Epoch 32/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.0473 - acc: 0.9943\n",
      "5105/5105 [==============================] - 1s 216us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45947/45947 [==============================] - 6s 136us/step - loss: 0.5019 - acc: 0.7599\n",
      "Epoch 2/32\n",
      "45947/45947 [==============================] - 3s 66us/step - loss: 0.3391 - acc: 0.8523\n",
      "Epoch 3/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 0.2564 - acc: 0.8979\n",
      "Epoch 4/32\n",
      "45947/45947 [==============================] - 3s 72us/step - loss: 0.2328 - acc: 0.9256\n",
      "Epoch 5/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.1685 - acc: 0.9438\n",
      "Epoch 6/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1453 - acc: 0.9597\n",
      "Epoch 7/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1205 - acc: 0.9672\n",
      "Epoch 8/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1124 - acc: 0.9734\n",
      "Epoch 9/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.1407 - acc: 0.9730\n",
      "Epoch 10/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.0896 - acc: 0.9782\n",
      "Epoch 11/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1109 - acc: 0.9781\n",
      "Epoch 12/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0998 - acc: 0.9818\n",
      "Epoch 13/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1297 - acc: 0.9795\n",
      "Epoch 14/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.1212 - acc: 0.9828\n",
      "Epoch 15/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.1101 - acc: 0.9788\n",
      "Epoch 16/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.0806 - acc: 0.9842\n",
      "Epoch 17/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1294 - acc: 0.9822\n",
      "Epoch 18/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1011 - acc: 0.9850\n",
      "Epoch 19/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1415 - acc: 0.9848\n",
      "Epoch 20/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1883 - acc: 0.9758\n",
      "Epoch 21/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.3552 - acc: 0.9681\n",
      "Epoch 22/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1111 - acc: 0.9847\n",
      "Epoch 23/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1246 - acc: 0.9844\n",
      "Epoch 24/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1055 - acc: 0.9849\n",
      "Epoch 25/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.0995 - acc: 0.9874\n",
      "Epoch 26/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.2957 - acc: 0.9696\n",
      "Epoch 27/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1325 - acc: 0.9866\n",
      "Epoch 28/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 1.0780 - acc: 0.9293\n",
      "Epoch 29/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 3.2151 - acc: 0.7964\n",
      "Epoch 30/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1035 - acc: 0.9882\n",
      "Epoch 31/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.0890 - acc: 0.9896\n",
      "Epoch 32/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.0523 - acc: 0.9927\n",
      "5105/5105 [==============================] - 1s 222us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45947/45947 [==============================] - 6s 138us/step - loss: 0.5346 - acc: 0.7368\n",
      "Epoch 2/32\n",
      "45947/45947 [==============================] - 3s 68us/step - loss: 0.3229 - acc: 0.8438\n",
      "Epoch 3/32\n",
      "45947/45947 [==============================] - 3s 66us/step - loss: 0.2945 - acc: 0.8784\n",
      "Epoch 4/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.2378 - acc: 0.9020\n",
      "Epoch 5/32\n",
      "45947/45947 [==============================] - 3s 72us/step - loss: 0.2057 - acc: 0.9184\n",
      "Epoch 6/32\n",
      "45947/45947 [==============================] - 3s 72us/step - loss: 0.2050 - acc: 0.9366\n",
      "Epoch 7/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.1530 - acc: 0.9482\n",
      "Epoch 8/32\n",
      "45947/45947 [==============================] - 4s 82us/step - loss: 0.1417 - acc: 0.9592\n",
      "Epoch 9/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1489 - acc: 0.9658\n",
      "Epoch 10/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1366 - acc: 0.9685\n",
      "Epoch 11/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.1163 - acc: 0.9752\n",
      "Epoch 12/32\n",
      "45947/45947 [==============================] - ETA: 0s - loss: 0.0985 - acc: 0.977 - 4s 82us/step - loss: 0.0983 - acc: 0.9773\n",
      "Epoch 13/32\n",
      "45947/45947 [==============================] - 4s 85us/step - loss: 0.0974 - acc: 0.9784\n",
      "Epoch 14/32\n",
      "45947/45947 [==============================] - 4s 85us/step - loss: 0.1079 - acc: 0.9797\n",
      "Epoch 15/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.1590 - acc: 0.9775\n",
      "Epoch 16/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.1386 - acc: 0.9793\n",
      "Epoch 17/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1318 - acc: 0.9815\n",
      "Epoch 18/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.7185 - acc: 0.9445\n",
      "Epoch 19/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1325 - acc: 0.9735\n",
      "Epoch 20/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1438 - acc: 0.9788\n",
      "Epoch 21/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1944 - acc: 0.9759\n",
      "Epoch 22/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.2088 - acc: 0.9778\n",
      "Epoch 23/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.7852 - acc: 0.9419\n",
      "Epoch 24/32\n",
      "45947/45947 [==============================] - 3s 71us/step - loss: 0.1227 - acc: 0.9824\n",
      "Epoch 25/32\n",
      "45947/45947 [==============================] - 3s 70us/step - loss: 0.3908 - acc: 0.9685\n",
      "Epoch 26/32\n",
      "45947/45947 [==============================] - 3s 72us/step - loss: 0.1438 - acc: 0.9849\n",
      "Epoch 27/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.2132 - acc: 0.9819\n",
      "Epoch 28/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1162 - acc: 0.9862\n",
      "Epoch 29/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.1226 - acc: 0.9849\n",
      "Epoch 30/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.1398 - acc: 0.9827\n",
      "Epoch 31/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.7854 - acc: 0.9467\n",
      "Epoch 32/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.1489 - acc: 0.9841\n",
      "5105/5105 [==============================] - 1s 241us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45947/45947 [==============================] - 7s 150us/step - loss: 0.4530 - acc: 0.7765\n",
      "Epoch 2/32\n",
      "45947/45947 [==============================] - 3s 75us/step - loss: 0.2936 - acc: 0.8741\n",
      "Epoch 3/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.2242 - acc: 0.9126\n",
      "Epoch 4/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.2074 - acc: 0.9344\n",
      "Epoch 5/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1872 - acc: 0.9471\n",
      "Epoch 6/32\n",
      "45947/45947 [==============================] - 4s 81us/step - loss: 0.1474 - acc: 0.9637\n",
      "Epoch 7/32\n",
      "45947/45947 [==============================] - 4s 85us/step - loss: 0.1217 - acc: 0.9707\n",
      "Epoch 8/32\n",
      "45947/45947 [==============================] - 4s 86us/step - loss: 0.0972 - acc: 0.9763\n",
      "Epoch 9/32\n",
      "45947/45947 [==============================] - 4s 84us/step - loss: 0.1014 - acc: 0.9788\n",
      "Epoch 10/32\n",
      "45947/45947 [==============================] - 4s 86us/step - loss: 0.0755 - acc: 0.9827\n",
      "Epoch 11/32\n",
      "45947/45947 [==============================] - 4s 88us/step - loss: 0.0696 - acc: 0.9838\n",
      "Epoch 12/32\n",
      "45947/45947 [==============================] - 4s 83us/step - loss: 0.0871 - acc: 0.9858\n",
      "Epoch 13/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1371 - acc: 0.9819\n",
      "Epoch 14/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.0744 - acc: 0.9841\n",
      "Epoch 15/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.0878 - acc: 0.9860\n",
      "Epoch 16/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1243 - acc: 0.9834\n",
      "Epoch 17/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.1241 - acc: 0.9849\n",
      "Epoch 18/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.0805 - acc: 0.9881\n",
      "Epoch 19/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1111 - acc: 0.9863\n",
      "Epoch 20/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.1322 - acc: 0.9806\n",
      "Epoch 21/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.1160 - acc: 0.9841\n",
      "Epoch 22/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.1130 - acc: 0.9832\n",
      "Epoch 23/32\n",
      "45947/45947 [==============================] - 4s 81us/step - loss: 0.1769 - acc: 0.9849\n",
      "Epoch 24/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.3325 - acc: 0.9727\n",
      "Epoch 25/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1847 - acc: 0.9809\n",
      "Epoch 26/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.4184 - acc: 0.9679\n",
      "Epoch 27/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.0767 - acc: 0.9871\n",
      "Epoch 28/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.0749 - acc: 0.9857\n",
      "Epoch 29/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.0698 - acc: 0.9900\n",
      "Epoch 30/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.0699 - acc: 0.9910\n",
      "Epoch 31/32\n",
      "45947/45947 [==============================] - 4s 85us/step - loss: 0.0645 - acc: 0.9925\n",
      "Epoch 32/32\n",
      "45947/45947 [==============================] - 4s 88us/step - loss: 0.0731 - acc: 0.9926\n",
      "5105/5105 [==============================] - 1s 241us/step\n",
      "!!!!!\n",
      "Epoch 1/32\n",
      "45947/45947 [==============================] - 7s 143us/step - loss: 0.5462 - acc: 0.7239\n",
      "Epoch 2/32\n",
      "45947/45947 [==============================] - 3s 68us/step - loss: 0.3565 - acc: 0.8360\n",
      "Epoch 3/32\n",
      "45947/45947 [==============================] - 3s 67us/step - loss: 0.4263 - acc: 0.8627\n",
      "Epoch 4/32\n",
      "45947/45947 [==============================] - 3s 67us/step - loss: 0.2737 - acc: 0.8997\n",
      "Epoch 5/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.2447 - acc: 0.9190\n",
      "Epoch 6/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.2083 - acc: 0.9289\n",
      "Epoch 7/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1712 - acc: 0.9470\n",
      "Epoch 8/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1574 - acc: 0.9551\n",
      "Epoch 9/32\n",
      "45947/45947 [==============================] - 4s 80us/step - loss: 0.1430 - acc: 0.9678\n",
      "Epoch 10/32\n",
      "45947/45947 [==============================] - 4s 83us/step - loss: 0.1238 - acc: 0.9697\n",
      "Epoch 11/32\n",
      "45947/45947 [==============================] - 4s 91us/step - loss: 0.1081 - acc: 0.9743\n",
      "Epoch 12/32\n",
      "45947/45947 [==============================] - 4s 87us/step - loss: 0.1249 - acc: 0.9727\n",
      "Epoch 13/32\n",
      "45947/45947 [==============================] - 4s 87us/step - loss: 0.1762 - acc: 0.9641\n",
      "Epoch 14/32\n",
      "45947/45947 [==============================] - 4s 87us/step - loss: 0.1811 - acc: 0.9736\n",
      "Epoch 15/32\n",
      "45947/45947 [==============================] - 4s 84us/step - loss: 0.1640 - acc: 0.9749\n",
      "Epoch 16/32\n",
      "45947/45947 [==============================] - 4s 82us/step - loss: 0.1828 - acc: 0.9711\n",
      "Epoch 17/32\n",
      "45947/45947 [==============================] - 3s 76us/step - loss: 0.1201 - acc: 0.9817\n",
      "Epoch 18/32\n",
      "45947/45947 [==============================] - 4s 79us/step - loss: 0.1079 - acc: 0.9777\n",
      "Epoch 19/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.0752 - acc: 0.9853\n",
      "Epoch 20/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1506 - acc: 0.9775\n",
      "Epoch 21/32\n",
      "45947/45947 [==============================] - 4s 78us/step - loss: 0.1514 - acc: 0.9743\n",
      "Epoch 22/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 0.1164 - acc: 0.9786\n",
      "Epoch 23/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 0.0939 - acc: 0.9852\n",
      "Epoch 24/32\n",
      "45947/45947 [==============================] - 3s 72us/step - loss: 0.2236 - acc: 0.9775\n",
      "Epoch 25/32\n",
      "45947/45947 [==============================] - 3s 73us/step - loss: 0.0960 - acc: 0.9862\n",
      "Epoch 26/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 1.3934 - acc: 0.9001\n",
      "Epoch 27/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 5.7768 - acc: 0.6376\n",
      "Epoch 28/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 5.7768 - acc: 0.6376\n",
      "Epoch 29/32\n",
      "45947/45947 [==============================] - 4s 77us/step - loss: 5.7768 - acc: 0.6376\n",
      "Epoch 30/32\n",
      "45947/45947 [==============================] - 4s 76us/step - loss: 5.7768 - acc: 0.6376\n",
      "Epoch 31/32\n",
      "45947/45947 [==============================] - 4s 84us/step - loss: 5.7768 - acc: 0.6376\n",
      "Epoch 32/32\n",
      "45947/45947 [==============================] - 4s 84us/step - loss: 5.7768 - acc: 0.6376\n",
      "5105/5105 [==============================] - 1s 274us/step\n",
      "!!!!!\n"
     ]
    }
   ],
   "source": [
    "DNNR10=[]\n",
    "precisionR10=[]\n",
    "recallR10=[]\n",
    "TruePositive10 =[]\n",
    "FalsePositive10 =[]\n",
    "for train, test in kf_total:\n",
    "    TrainX=pd.DataFrame(LassoInput[list(train),:])\n",
    "    Trainy=pd.DataFrame(output[list(train)])\n",
    "    TestX=pd.DataFrame(LassoInput[list(test),:])\n",
    "    Testy=pd.DataFrame(output[list(test)])\n",
    "    \n",
    "    model,score, precision, recall, TN, FP, FN, TP, yPredict=DNN(np.array(TrainX), np.array(Trainy)\n",
    "                    , \n",
    "                    np.array(TestX),np.array(Testy)\n",
    "                    ,len(commonLassoFeatures))\n",
    "    DNNR10.append(score)\n",
    "    precisionR10.append(precision)\n",
    "    recallR10.append(recall)\n",
    "    TruePositive10.append(TP)\n",
    "    FalsePositive10.append(FP)\n",
    "    print(\"!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.861050739024\n",
      "Precision\n",
      "0.823966532092\n",
      "ReCall\n",
      "0.899295196016\n",
      "TruePositive\n",
      "2928.0\n",
      "False Posisive\n",
      "381.1\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:\")\n",
    "print(np.mean(DNNR10))\n",
    "print(\"Precision\")\n",
    "print(np.mean(precisionR10))\n",
    "print(\"ReCall\")\n",
    "print(np.mean(recallR10))\n",
    "print(\"TruePositive\")\n",
    "print(np.mean(TruePositive10) )\n",
    "print(\"False Posisive\")\n",
    "print(np.mean(FalsePositive10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Score for each Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Features Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 112us/step - loss: 0.6488 - acc: 0.6394\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6344 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6260 - acc: 0.6397\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6203 - acc: 0.6444\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6167 - acc: 0.6423\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6145 - acc: 0.6343\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6133 - acc: 0.6510\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6127 - acc: 0.6686\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6123 - acc: 0.6804\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6121 - acc: 0.6828\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6118 - acc: 0.6847\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6119 - acc: 0.6892\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6119 - acc: 0.6883: 0s - loss: 0.\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6117 - acc: 0.6894\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6118 - acc: 0.6895\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6117 - acc: 0.6891\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6117 - acc: 0.6908\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6115 - acc: 0.6905\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6115 - acc: 0.6896\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6115 - acc: 0.6899\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6113 - acc: 0.6914\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6115 - acc: 0.6906\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6113 - acc: 0.6917\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6113 - acc: 0.6915\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6114 - acc: 0.6904\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6113 - acc: 0.6912\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6113 - acc: 0.6898\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6113 - acc: 0.6914\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6112 - acc: 0.6896\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6112 - acc: 0.6940\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6111 - acc: 0.6914\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6112 - acc: 0.6911\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6112 - acc: 0.6913\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6112 - acc: 0.6919\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6110 - acc: 0.6937\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6109 - acc: 0.6923\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6111 - acc: 0.6911\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6111 - acc: 0.6918: 1s - loss:\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6111 - acc: 0.6908\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6111 - acc: 0.6918\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6111 - acc: 0.6922\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6111 - acc: 0.6927\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6112 - acc: 0.6913\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6111 - acc: 0.6915\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6111 - acc: 0.6916\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6109 - acc: 0.6930\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6111 - acc: 0.6908: 0s - loss: 0.6109 - acc: 0.690\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6108 - acc: 0.6925\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6110 - acc: 0.6921\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6109 - acc: 0.6905\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6110 - acc: 0.6944\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6111 - acc: 0.6913\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6110 - acc: 0.6903\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6109 - acc: 0.6915\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6108 - acc: 0.6935\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6110 - acc: 0.6919\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6110 - acc: 0.6915\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6109 - acc: 0.6934\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6108 - acc: 0.6923\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6109 - acc: 0.6934\n",
      "15316/15316 [==============================] - 2s 151us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 108us/step - loss: 0.6536 - acc: 0.6394\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6528 - acc: 0.6394\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6528 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6527 - acc: 0.6394\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6527 - acc: 0.6394\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6527 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6527 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6526 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6527 - acc: 0.6394\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6526 - acc: 0.6394\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6525 - acc: 0.6394: 1s - loss: \n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6526 - acc: 0.6394\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6524 - acc: 0.6394: 1s - loss: \n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6521 - acc: 0.6394\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6521 - acc: 0.6394\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6521 - acc: 0.6394\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6522 - acc: 0.6394\n",
      "15316/15316 [==============================] - 2s 158us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 104us/step - loss: 0.6514 - acc: 0.6394\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6485 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6484 - acc: 0.6394\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6484 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6483 - acc: 0.6394\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6483 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6483 - acc: 0.6394\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6483 - acc: 0.6394\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6483 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6483 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6483 - acc: 0.6394\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6480 - acc: 0.6394\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6394\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6481 - acc: 0.6394\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6482 - acc: 0.6394\n",
      "15316/15316 [==============================] - 3s 170us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 104us/step - loss: 0.5661 - acc: 0.6275\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.3611 - acc: 0.9903\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.2419 - acc: 0.9988\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.1477 - acc: 0.9980\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.0830 - acc: 0.9980\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.0472 - acc: 0.9980\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.0278 - acc: 0.9982\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.0172 - acc: 0.9986\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.0117 - acc: 0.9990\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.0084 - acc: 0.9992\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.0063 - acc: 0.9993\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.0049 - acc: 0.9994\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.0040 - acc: 0.9994\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.0034 - acc: 0.9995\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.0010 - acc: 0.9998\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 9.6179e-04 - acc: 0.9999\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 9.0854e-04 - acc: 0.9999\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 8.5935e-04 - acc: 0.9999\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - ETA: 0s - loss: 8.3814e-04 - acc: 0.999 - 1s 39us/step - loss: 8.2901e-04 - acc: 0.9999\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 7.8948e-04 - acc: 0.9999\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 7.4477e-04 - acc: 0.9999\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 6.9062e-04 - acc: 0.9999\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 6.6964e-04 - acc: 0.9999\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 6.2941e-04 - acc: 0.9999\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 6.0789e-04 - acc: 0.9999\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 5.4931e-04 - acc: 0.9999\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 5.4082e-04 - acc: 0.9999\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 5.2769e-04 - acc: 0.9999: 1s - loss: 6.8851\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 5.1048e-04 - acc: 0.9999\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 4.8368e-04 - acc: 0.9999\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 4.4536e-04 - acc: 0.9999\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 4.2397e-04 - acc: 0.9999\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 4.2253e-04 - acc: 0.9999\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 4.0270e-04 - acc: 0.9999: 1s - loss: 2.9\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 3.7679e-04 - acc: 0.9999\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 3.6333e-04 - acc: 0.9999\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 3.7074e-04 - acc: 0.9999\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 3.4969e-04 - acc: 0.9999\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 3.3831e-04 - acc: 0.9999\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 3.2966e-04 - acc: 0.9999\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 3.2159e-04 - acc: 0.9999\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 3.0292e-04 - acc: 0.9999\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 3.0265e-04 - acc: 0.9999\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 2.7266e-04 - acc: 0.9999\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 2.7589e-04 - acc: 0.9999\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 2.9101e-04 - acc: 0.9999\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 2.7506e-04 - acc: 0.9999\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 2.6724e-04 - acc: 0.9999\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 2.6577e-04 - acc: 0.9999\n",
      "15316/15316 [==============================] - 2s 157us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 108us/step - loss: 0.6593 - acc: 0.6394\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6516 - acc: 0.6394\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6506 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6500 - acc: 0.6394\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6495 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6491 - acc: 0.6394\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6489 - acc: 0.6394\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6487 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6484 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6484 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6397\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6392\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6481 - acc: 0.6396\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6480 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6479 - acc: 0.6390\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6479 - acc: 0.6390\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6479 - acc: 0.6380\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6478 - acc: 0.6387\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6476 - acc: 0.6387\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6477 - acc: 0.6387\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6476 - acc: 0.6397\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6475 - acc: 0.6381\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6475 - acc: 0.6389\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6475 - acc: 0.6397\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6474 - acc: 0.6395\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6473 - acc: 0.6397\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6472 - acc: 0.6397\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6472 - acc: 0.6400\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6472 - acc: 0.6387\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6472 - acc: 0.6399\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6471 - acc: 0.6386\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6471 - acc: 0.6399\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6471 - acc: 0.6392\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6470 - acc: 0.6398\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6470 - acc: 0.6398\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6470 - acc: 0.6398\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6469 - acc: 0.6394\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6469 - acc: 0.6399\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6469 - acc: 0.6404\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6468 - acc: 0.6415\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6468 - acc: 0.6397\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6468 - acc: 0.6410\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6468 - acc: 0.6403\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6467 - acc: 0.6409\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6466 - acc: 0.6407\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6466 - acc: 0.6410\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6467 - acc: 0.6411\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6466 - acc: 0.6412\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6465 - acc: 0.6410\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6464 - acc: 0.6395\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6466 - acc: 0.6418\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6466 - acc: 0.6411\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6465 - acc: 0.6416\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6465 - acc: 0.6417\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6465 - acc: 0.6424\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6465 - acc: 0.6416\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6464 - acc: 0.6427\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6464 - acc: 0.6429\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6464 - acc: 0.6426\n",
      "15316/15316 [==============================] - 3s 171us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 104us/step - loss: 0.6549 - acc: 0.6394\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6537 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6536 - acc: 0.6394\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6536 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6535 - acc: 0.6394\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6535 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6535 - acc: 0.6394\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6534 - acc: 0.6394\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6534 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6534 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6533 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6533 - acc: 0.6394\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6533 - acc: 0.6394\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6532 - acc: 0.6394\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6532 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6533 - acc: 0.6394\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6532 - acc: 0.6394\n",
      "Epoch 18/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6532 - acc: 0.6394\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - ETA: 0s - loss: 0.6535 - acc: 0.638 - 1s 36us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6530 - acc: 0.6394: 1s - loss\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6529 - acc: 0.6395\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6529 - acc: 0.6395\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6529 - acc: 0.6396\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6529 - acc: 0.6396\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6529 - acc: 0.6395\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6528 - acc: 0.6396\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6529 - acc: 0.6396\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6528 - acc: 0.6396\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6529 - acc: 0.6396\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6528 - acc: 0.6396\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6528 - acc: 0.6395\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6528 - acc: 0.6394\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6528 - acc: 0.6396\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6529 - acc: 0.6395\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6528 - acc: 0.6397\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6529 - acc: 0.6397\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6528 - acc: 0.6398\n",
      "15316/15316 [==============================] - 3s 196us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 114us/step - loss: 0.6882 - acc: 0.5533\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6193 - acc: 0.6442\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5992 - acc: 0.6512\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.5916 - acc: 0.6512\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5894 - acc: 0.6512\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5884 - acc: 0.6512\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.5874 - acc: 0.6512\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5867 - acc: 0.6508\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5860 - acc: 0.6507\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5854 - acc: 0.6540\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.5851 - acc: 0.6516\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5847 - acc: 0.6552\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.5844 - acc: 0.6619\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5842 - acc: 0.6630\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5840 - acc: 0.6651\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5839 - acc: 0.6642\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5837 - acc: 0.6646\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5837 - acc: 0.6694\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5836 - acc: 0.6670\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5835 - acc: 0.6688: 1s - loss: 0\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5835 - acc: 0.6686\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5835 - acc: 0.6689\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5834 - acc: 0.6693\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5834 - acc: 0.6690\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5834 - acc: 0.6691\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5833 - acc: 0.6687\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5833 - acc: 0.6694\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5833 - acc: 0.6692\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5833 - acc: 0.6691\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5833 - acc: 0.6689\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5833 - acc: 0.6692\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5833 - acc: 0.6692\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5833 - acc: 0.6690\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5832 - acc: 0.6692\n",
      "Epoch 38/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5832 - acc: 0.6688\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5832 - acc: 0.6692\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - ETA: 0s - loss: 0.5824 - acc: 0.670 - 1s 33us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5832 - acc: 0.6693\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5833 - acc: 0.6693\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5832 - acc: 0.6693\n",
      "15316/15316 [==============================] - 3s 168us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 117us/step - loss: 0.6502 - acc: 0.6394\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6212 - acc: 0.6318\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6039 - acc: 0.6201\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.5919 - acc: 0.6103\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.5803 - acc: 0.6103\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.5688 - acc: 0.6103\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.5581 - acc: 0.6103\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.5483 - acc: 0.6110\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.5400 - acc: 0.6135\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.5335 - acc: 0.6185: 0s - loss: 0.54\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.5286 - acc: 0.6237\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5248 - acc: 0.6251\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5218 - acc: 0.6250\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5194 - acc: 0.6271\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5179 - acc: 0.6283\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5166 - acc: 0.6294\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5157 - acc: 0.6311\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5148 - acc: 0.6335\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5145 - acc: 0.6390\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5141 - acc: 0.6388\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5138 - acc: 0.6413\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5135 - acc: 0.6444\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5134 - acc: 0.6449\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5132 - acc: 0.6449\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5131 - acc: 0.6442\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5130 - acc: 0.6423\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5129 - acc: 0.6415\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5128 - acc: 0.6436\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5127 - acc: 0.6466\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5127 - acc: 0.6455\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5126 - acc: 0.6464\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5126 - acc: 0.6447\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.5125 - acc: 0.6485\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.5125 - acc: 0.6448\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.5125 - acc: 0.6452\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 42us/step - loss: 0.5125 - acc: 0.6455\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.5125 - acc: 0.6467\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.5124 - acc: 0.6466\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5124 - acc: 0.6448\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.5124 - acc: 0.6455\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5124 - acc: 0.6425\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5123 - acc: 0.6468\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5122 - acc: 0.6471\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5123 - acc: 0.6446\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5123 - acc: 0.6485\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5123 - acc: 0.6435\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5123 - acc: 0.6437\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5123 - acc: 0.6464\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5123 - acc: 0.6465\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5123 - acc: 0.6450\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5123 - acc: 0.6464\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5121 - acc: 0.6467\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5122 - acc: 0.6449\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5122 - acc: 0.6431\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5121 - acc: 0.6480\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5122 - acc: 0.6430\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5122 - acc: 0.6419\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5121 - acc: 0.6471\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5121 - acc: 0.6472\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5121 - acc: 0.6456\n",
      "15316/15316 [==============================] - 3s 190us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 108us/step - loss: 0.6552 - acc: 0.6261\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.6502 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6494 - acc: 0.6394\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.6486 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6477 - acc: 0.6394\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6468 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6458 - acc: 0.6394\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6445 - acc: 0.6394\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6435 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6417 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6399 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6382 - acc: 0.6394\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6364 - acc: 0.6394\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6338 - acc: 0.6394\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6316 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6290 - acc: 0.6394\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6260 - acc: 0.6394\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6230 - acc: 0.6394: 0s - loss: 0.6249 - acc\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6195 - acc: 0.6394\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.6161 - acc: 0.6394\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6126 - acc: 0.6394\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6087 - acc: 0.6394\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6045 - acc: 0.6394\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6004 - acc: 0.6394\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5958 - acc: 0.6394\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5917 - acc: 0.6394\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.5869 - acc: 0.6396\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.5818 - acc: 0.6401\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5771 - acc: 0.6431\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5716 - acc: 0.6441\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5661 - acc: 0.6444\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5603 - acc: 0.6488\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5551 - acc: 0.6524\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5490 - acc: 0.6622\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5439 - acc: 0.6636\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5380 - acc: 0.6744\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5315 - acc: 0.6905\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5257 - acc: 0.6996\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5201 - acc: 0.7097\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5145 - acc: 0.7164\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5078 - acc: 0.7343\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5018 - acc: 0.7478\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.4954 - acc: 0.7611\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.4891 - acc: 0.7736\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.4837 - acc: 0.7850\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.4779 - acc: 0.7985\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.4713 - acc: 0.8122\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.4656 - acc: 0.8221\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.4597 - acc: 0.8343\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.4534 - acc: 0.8448\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.4474 - acc: 0.8561\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.4420 - acc: 0.8589\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.4356 - acc: 0.8662\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.4291 - acc: 0.8801\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.4247 - acc: 0.8829\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.4176 - acc: 0.8936\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 2s 43us/step - loss: 0.4135 - acc: 0.8966\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.4081 - acc: 0.9026\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 2s 47us/step - loss: 0.4026 - acc: 0.9103\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 2s 49us/step - loss: 0.3976 - acc: 0.9120\n",
      "15316/15316 [==============================] - 5s 313us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 7s 190us/step - loss: 0.6356 - acc: 0.6362\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.6211 - acc: 0.6408\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.6186 - acc: 0.6554\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6178 - acc: 0.6579\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.6174 - acc: 0.6631\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6172 - acc: 0.6635\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6171 - acc: 0.6640\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6170 - acc: 0.6649\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6170 - acc: 0.6640\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6169 - acc: 0.6644\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6169 - acc: 0.6635\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6168 - acc: 0.6650\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6169 - acc: 0.6648\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6168 - acc: 0.6643\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6168 - acc: 0.6648\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6168 - acc: 0.6647\n",
      "Epoch 17/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6168 - acc: 0.6648\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6168 - acc: 0.6636\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6168 - acc: 0.6648\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6168 - acc: 0.6640\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6168 - acc: 0.6643\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6168 - acc: 0.6641\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6167 - acc: 0.6631\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6167 - acc: 0.6642\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6167 - acc: 0.6644\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6168 - acc: 0.6640\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6168 - acc: 0.6640\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6167 - acc: 0.6631\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 2s 43us/step - loss: 0.6168 - acc: 0.6645\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6167 - acc: 0.6635\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6167 - acc: 0.6644\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6168 - acc: 0.6641\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6168 - acc: 0.6633\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.6168 - acc: 0.6639\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 2s 45us/step - loss: 0.6167 - acc: 0.6629\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.6168 - acc: 0.6633\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.6167 - acc: 0.6639\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 2s 50us/step - loss: 0.6168 - acc: 0.6634\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.6167 - acc: 0.6634\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.6167 - acc: 0.6631\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.6168 - acc: 0.6630\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 2s 56us/step - loss: 0.6167 - acc: 0.6635\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.6167 - acc: 0.6644\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 2s 55us/step - loss: 0.6167 - acc: 0.6634\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 2s 60us/step - loss: 0.6168 - acc: 0.6629\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 2s 50us/step - loss: 0.6167 - acc: 0.6641\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 2s 47us/step - loss: 0.6167 - acc: 0.6638\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.6167 - acc: 0.6634\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 2s 64us/step - loss: 0.6167 - acc: 0.6634\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.6168 - acc: 0.6632\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 2s 50us/step - loss: 0.6167 - acc: 0.6641\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.6167 - acc: 0.6631\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6167 - acc: 0.6639\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6167 - acc: 0.6630\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6167 - acc: 0.6641\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 2s 42us/step - loss: 0.6167 - acc: 0.6636\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 2s 43us/step - loss: 0.6167 - acc: 0.6633\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.6167 - acc: 0.6635\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6167 - acc: 0.6632\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6168 - acc: 0.6631\n",
      "15316/15316 [==============================] - 4s 283us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 6s 157us/step - loss: 0.6501 - acc: 0.6129\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5101 - acc: 0.8497\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.4416 - acc: 0.8439\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.4162 - acc: 0.8439\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.4089 - acc: 0.8439\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.4055 - acc: 0.8439\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 2s 43us/step - loss: 0.4031 - acc: 0.8439\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 2s 49us/step - loss: 0.4014 - acc: 0.8441\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 0.3998 - acc: 0.8439\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 0.3985 - acc: 0.8439\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 2s 45us/step - loss: 0.3973 - acc: 0.8445\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.3963 - acc: 0.8448\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 2s 42us/step - loss: 0.3954 - acc: 0.8463\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.3945 - acc: 0.8467: 1s - loss: 0.4036 - acc: 0.84 - ETA: 1s -\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.3937 - acc: 0.8480\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 0.3929 - acc: 0.8506\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3924 - acc: 0.8510\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 2s 45us/step - loss: 0.3919 - acc: 0.8513\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3911 - acc: 0.8528\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 2s 47us/step - loss: 0.3908 - acc: 0.8543\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.3904 - acc: 0.8559\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 2s 54us/step - loss: 0.3898 - acc: 0.8560\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 2s 50us/step - loss: 0.3894 - acc: 0.8553\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 2s 48us/step - loss: 0.3891 - acc: 0.8566\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 2s 63us/step - loss: 0.3889 - acc: 0.8570\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 2s 59us/step - loss: 0.3886 - acc: 0.8570\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 2s 60us/step - loss: 0.3882 - acc: 0.8572\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.3881 - acc: 0.8573\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 2s 52us/step - loss: 0.3878 - acc: 0.8572\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.3876 - acc: 0.8573\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 2s 61us/step - loss: 0.3873 - acc: 0.8571\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.3872 - acc: 0.8573\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.3870 - acc: 0.8573\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 2s 62us/step - loss: 0.3868 - acc: 0.8573\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 2s 58us/step - loss: 0.3868 - acc: 0.8573\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 2s 57us/step - loss: 0.3865 - acc: 0.8573\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 2s 53us/step - loss: 0.3864 - acc: 0.8573\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 2s 61us/step - loss: 0.3864 - acc: 0.8573\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3862 - acc: 0.8573\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3861 - acc: 0.8573\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3860 - acc: 0.8573\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 2s 51us/step - loss: 0.3858 - acc: 0.8573\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 2s 47us/step - loss: 0.3858 - acc: 0.8573\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3857 - acc: 0.8573\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3856 - acc: 0.8573\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.3856 - acc: 0.8573\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 2s 44us/step - loss: 0.3854 - acc: 0.8573\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 2s 47us/step - loss: 0.3854 - acc: 0.8573\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3853 - acc: 0.8573\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3853 - acc: 0.8573\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 2s 42us/step - loss: 0.3852 - acc: 0.8573\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3852 - acc: 0.8573\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 2s 45us/step - loss: 0.3851 - acc: 0.8573\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 2s 47us/step - loss: 0.3850 - acc: 0.8573\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 2s 47us/step - loss: 0.3849 - acc: 0.8573\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 2s 46us/step - loss: 0.3849 - acc: 0.8573\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - ETA: 0s - loss: 0.3836 - acc: 0.857 - 1s 42us/step - loss: 0.3849 - acc: 0.8573\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 2s 42us/step - loss: 0.3848 - acc: 0.8573\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.3848 - acc: 0.8573\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.3848 - acc: 0.8573\n",
      "15316/15316 [==============================] - 5s 306us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 124us/step - loss: 0.5762 - acc: 0.7044\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.4746 - acc: 0.8087\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.4285 - acc: 0.8110\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.4084 - acc: 0.8132\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.4026 - acc: 0.8132\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 26us/step - loss: 0.4008 - acc: 0.8099\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.4000 - acc: 0.8104\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.3996 - acc: 0.8125\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.3993 - acc: 0.8118\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.3990 - acc: 0.8114\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.3988 - acc: 0.8123\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.3986 - acc: 0.8134\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.3985 - acc: 0.8137\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.3983 - acc: 0.8134\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.3982 - acc: 0.8131\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.3979 - acc: 0.8130\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.3977 - acc: 0.8124\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.3976 - acc: 0.8127\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.3974 - acc: 0.8127\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.3972 - acc: 0.8121\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.3971 - acc: 0.8130\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.3968 - acc: 0.8137\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.3966 - acc: 0.8130\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.3963 - acc: 0.8128\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.3962 - acc: 0.8130\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.3959 - acc: 0.8129\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.3953 - acc: 0.8124\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.3954 - acc: 0.8126\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.3950 - acc: 0.8125\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.3949 - acc: 0.8138\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.3945 - acc: 0.8137\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.3943 - acc: 0.8134\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.3938 - acc: 0.8115: 1s - loss: \n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.3936 - acc: 0.8130\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.3932 - acc: 0.8119\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.3929 - acc: 0.8124\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.3926 - acc: 0.8110\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.3923 - acc: 0.8126\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.3921 - acc: 0.8131\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.3917 - acc: 0.8116\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.3913 - acc: 0.8106\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.3910 - acc: 0.8106\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.3908 - acc: 0.8119\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.3905 - acc: 0.8111\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.3903 - acc: 0.8116\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.3900 - acc: 0.8118\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.3897 - acc: 0.8102\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.3895 - acc: 0.8113\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.3892 - acc: 0.8096\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.3890 - acc: 0.8119\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.3887 - acc: 0.8093\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.3886 - acc: 0.8095\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.3885 - acc: 0.8108\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.3880 - acc: 0.8088\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.3880 - acc: 0.8092\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.3878 - acc: 0.8094\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.3877 - acc: 0.8102\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.3875 - acc: 0.8093\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.3871 - acc: 0.8083\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.3869 - acc: 0.8076\n",
      "15316/15316 [==============================] - 3s 218us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 122us/step - loss: 0.6686 - acc: 0.5989\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6533 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6527 - acc: 0.6394\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6524 - acc: 0.6394\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6521 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6516 - acc: 0.6394\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6515 - acc: 0.6394\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6515 - acc: 0.6394\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6514 - acc: 0.6394\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6513 - acc: 0.6394\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6514 - acc: 0.6394\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6512 - acc: 0.6394\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6512 - acc: 0.6394\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6512 - acc: 0.6393\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6512 - acc: 0.6393\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6511 - acc: 0.6393\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6511 - acc: 0.6392\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6510 - acc: 0.6393\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6510 - acc: 0.6392\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6508 - acc: 0.6392\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6508 - acc: 0.6392\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6508 - acc: 0.6392\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6508 - acc: 0.6392\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6508 - acc: 0.6392\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6508 - acc: 0.6392\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6508 - acc: 0.6392\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6509 - acc: 0.6392\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6507 - acc: 0.6392\n",
      "15316/15316 [==============================] - 3s 190us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 124us/step - loss: 0.7493 - acc: 0.5030\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6575 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6644 - acc: 0.6174\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6561 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6634 - acc: 0.6147\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6524 - acc: 0.6397\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6850 - acc: 0.5355\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6565 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6543 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6570 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6611 - acc: 0.6312\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6542 - acc: 0.6394\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6538 - acc: 0.6394\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6536 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6584 - acc: 0.6394\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6572 - acc: 0.6394\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6547 - acc: 0.6394\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6538 - acc: 0.6394\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6570 - acc: 0.6380\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6606 - acc: 0.6286\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6542 - acc: 0.6394\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6539 - acc: 0.6394\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6564 - acc: 0.6394\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6540 - acc: 0.6394\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6550 - acc: 0.6394\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6560 - acc: 0.6394\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6549 - acc: 0.6394\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6547 - acc: 0.6394\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6548 - acc: 0.6394\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - ETA: 0s - loss: 0.6549 - acc: 0.638 - 1s 35us/step - loss: 0.6545 - acc: 0.6394\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6539 - acc: 0.6394\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6540 - acc: 0.6394\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6539 - acc: 0.6394\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6537 - acc: 0.6394\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6572 - acc: 0.6394\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6544 - acc: 0.6394\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6549 - acc: 0.6394\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6545 - acc: 0.6394\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6548 - acc: 0.6394: 1s - \n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6540 - acc: 0.6394\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6540 - acc: 0.6394\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6539 - acc: 0.6394\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6540 - acc: 0.6394\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6540 - acc: 0.6394\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6539 - acc: 0.6394\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6540 - acc: 0.6394\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6539 - acc: 0.6394\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6539 - acc: 0.6394\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6541 - acc: 0.6394\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6541 - acc: 0.6394\n",
      "15316/15316 [==============================] - 3s 176us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 5s 131us/step - loss: 0.6589 - acc: 0.6244\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6525 - acc: 0.6394\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6523 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6522 - acc: 0.6394\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6521 - acc: 0.6394\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6521 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6520 - acc: 0.6394\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 2s 43us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 37/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6517 - acc: 0.6394\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6516 - acc: 0.6394\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6519 - acc: 0.6394\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6518 - acc: 0.6394\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6517 - acc: 0.6394\n",
      "15316/15316 [==============================] - 3s 167us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 121us/step - loss: 0.6744 - acc: 0.6085\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6064 - acc: 0.7114\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.5955 - acc: 0.7184\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.5886 - acc: 0.7184\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.5838 - acc: 0.7129\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5810 - acc: 0.7098\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.5793 - acc: 0.7081\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.5780 - acc: 0.7080\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.5772 - acc: 0.7071\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5764 - acc: 0.7076\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5758 - acc: 0.7081\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5753 - acc: 0.7078\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5749 - acc: 0.7068\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5745 - acc: 0.7092\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5743 - acc: 0.7084\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5741 - acc: 0.7071\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5737 - acc: 0.7086\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5736 - acc: 0.7075\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5734 - acc: 0.7085\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5731 - acc: 0.7081\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5731 - acc: 0.7070\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5729 - acc: 0.7073\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5728 - acc: 0.7079\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5727 - acc: 0.7070\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5725 - acc: 0.7077\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5725 - acc: 0.7074\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5723 - acc: 0.7088\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.5723 - acc: 0.7072\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.5722 - acc: 0.7081\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.5721 - acc: 0.7089\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.5720 - acc: 0.7073\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.5720 - acc: 0.7076\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.5719 - acc: 0.7095\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.5719 - acc: 0.7075\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - ETA: 0s - loss: 0.5715 - acc: 0.708 - 1s 39us/step - loss: 0.5718 - acc: 0.7083\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.5717 - acc: 0.7100\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.5717 - acc: 0.7096\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.5716 - acc: 0.7086\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5716 - acc: 0.7075\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5716 - acc: 0.7080\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.5715 - acc: 0.7071\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5714 - acc: 0.7082\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5714 - acc: 0.7077\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5714 - acc: 0.7096\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5712 - acc: 0.7090\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5713 - acc: 0.7077\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5712 - acc: 0.7070\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.5712 - acc: 0.7077\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5712 - acc: 0.7097\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5712 - acc: 0.7117\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5712 - acc: 0.7070\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.5711 - acc: 0.7088\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.5710 - acc: 0.7098\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5710 - acc: 0.7096\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.5710 - acc: 0.7082\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5710 - acc: 0.7108\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.5709 - acc: 0.7091\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5709 - acc: 0.7078\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.5709 - acc: 0.7082\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.5709 - acc: 0.7089\n",
      "15316/15316 [==============================] - 3s 182us/step\n",
      "Epoch 1/60\n",
      "35736/35736 [==============================] - 4s 122us/step - loss: 0.6538 - acc: 0.6394\n",
      "Epoch 2/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6537 - acc: 0.6394\n",
      "Epoch 3/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6536 - acc: 0.6394\n",
      "Epoch 4/60\n",
      "35736/35736 [==============================] - 1s 29us/step - loss: 0.6534 - acc: 0.6394\n",
      "Epoch 5/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6533 - acc: 0.6394\n",
      "Epoch 6/60\n",
      "35736/35736 [==============================] - 1s 28us/step - loss: 0.6533 - acc: 0.6394\n",
      "Epoch 7/60\n",
      "35736/35736 [==============================] - 1s 27us/step - loss: 0.6532 - acc: 0.6394\n",
      "Epoch 8/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 9/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6531 - acc: 0.6394\n",
      "Epoch 10/60\n",
      "35736/35736 [==============================] - 1s 30us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 11/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6530 - acc: 0.6394\n",
      "Epoch 12/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 13/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6528 - acc: 0.6394\n",
      "Epoch 14/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6529 - acc: 0.6394\n",
      "Epoch 15/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6528 - acc: 0.6394\n",
      "Epoch 16/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6528 - acc: 0.6394\n",
      "Epoch 17/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6527 - acc: 0.6394\n",
      "Epoch 18/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6527 - acc: 0.6394\n",
      "Epoch 19/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6526 - acc: 0.6394\n",
      "Epoch 20/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6525 - acc: 0.6395\n",
      "Epoch 21/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6526 - acc: 0.6395\n",
      "Epoch 22/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6525 - acc: 0.6395\n",
      "Epoch 23/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6524 - acc: 0.6395\n",
      "Epoch 24/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6524 - acc: 0.6395\n",
      "Epoch 25/60\n",
      "35736/35736 [==============================] - 2s 43us/step - loss: 0.6523 - acc: 0.6395\n",
      "Epoch 26/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.6523 - acc: 0.6395\n",
      "Epoch 27/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6521 - acc: 0.6396\n",
      "Epoch 28/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.6522 - acc: 0.6396\n",
      "Epoch 29/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6521 - acc: 0.6396\n",
      "Epoch 30/60\n",
      "35736/35736 [==============================] - 1s 40us/step - loss: 0.6521 - acc: 0.6397\n",
      "Epoch 31/60\n",
      "35736/35736 [==============================] - 1s 41us/step - loss: 0.6520 - acc: 0.6397\n",
      "Epoch 32/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6518 - acc: 0.6400\n",
      "Epoch 33/60\n",
      "35736/35736 [==============================] - 1s 39us/step - loss: 0.6519 - acc: 0.6400\n",
      "Epoch 34/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6518 - acc: 0.6402\n",
      "Epoch 35/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6518 - acc: 0.6404\n",
      "Epoch 36/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6518 - acc: 0.6405\n",
      "Epoch 37/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6518 - acc: 0.6406\n",
      "Epoch 38/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6517 - acc: 0.6406\n",
      "Epoch 39/60\n",
      "35736/35736 [==============================] - 1s 37us/step - loss: 0.6516 - acc: 0.6406\n",
      "Epoch 40/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6516 - acc: 0.6406\n",
      "Epoch 41/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6514 - acc: 0.6407\n",
      "Epoch 42/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6515 - acc: 0.6406\n",
      "Epoch 43/60\n",
      "35736/35736 [==============================] - 1s 36us/step - loss: 0.6514 - acc: 0.6406\n",
      "Epoch 44/60\n",
      "35736/35736 [==============================] - 1s 34us/step - loss: 0.6514 - acc: 0.6406\n",
      "Epoch 45/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6513 - acc: 0.6407\n",
      "Epoch 46/60\n",
      "35736/35736 [==============================] - 1s 38us/step - loss: 0.6512 - acc: 0.6408\n",
      "Epoch 47/60\n",
      "35736/35736 [==============================] - 1s 35us/step - loss: 0.6512 - acc: 0.6408\n",
      "Epoch 48/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6510 - acc: 0.6407\n",
      "Epoch 49/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6510 - acc: 0.6411\n",
      "Epoch 50/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6509 - acc: 0.6410\n",
      "Epoch 51/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6508 - acc: 0.6410\n",
      "Epoch 52/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6508 - acc: 0.6410\n",
      "Epoch 53/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6508 - acc: 0.6413\n",
      "Epoch 54/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6506 - acc: 0.6413\n",
      "Epoch 55/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6505 - acc: 0.6414\n",
      "Epoch 56/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6506 - acc: 0.6412\n",
      "Epoch 57/60\n",
      "35736/35736 [==============================] - 1s 32us/step - loss: 0.6504 - acc: 0.6415\n",
      "Epoch 58/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6503 - acc: 0.6415\n",
      "Epoch 59/60\n",
      "35736/35736 [==============================] - 1s 31us/step - loss: 0.6504 - acc: 0.6416\n",
      "Epoch 60/60\n",
      "35736/35736 [==============================] - 1s 33us/step - loss: 0.6503 - acc: 0.6416\n",
      "15316/15316 [==============================] - 3s 189us/step\n"
     ]
    }
   ],
   "source": [
    "LassoDict= dict()\n",
    "for l in commonLassoFeatures:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        Input[l],\n",
    "                output, test_size=0.3, random_state=5)\n",
    "    score=NNModelFunction(X_train,y_train, X_test, y_test,1)\n",
    "    LassoDict[l]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AlignLen': (<keras.models.Sequential at 0x11f661550>,\n",
       "  0.62137633850070761,\n",
       "  0.6376811594202898,\n",
       "  0.93318233295583242,\n",
       "  453,\n",
       "  5150,\n",
       "  649,\n",
       "  9064,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [0],\n",
       "         [1]], dtype=int32)),\n",
       " 'Energy': (<keras.models.Sequential at 0x147a7cc50>,\n",
       "  0.99993470880125357,\n",
       "  1.0,\n",
       "  0.9998970451971585,\n",
       "  5603,\n",
       "  0,\n",
       "  1,\n",
       "  9712,\n",
       "  array([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'Score': (<keras.models.Sequential at 0x160109c50>,\n",
       "  0.73694176025071823,\n",
       "  0.70681123562800174,\n",
       "  1.0,\n",
       "  1574,\n",
       "  4029,\n",
       "  0,\n",
       "  9713,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [0],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'Tot_Mat': (<keras.models.Sequential at 0x15e64e0f0>,\n",
       "  0.64879864194306602,\n",
       "  0.7793965961835998,\n",
       "  0.62236178317718527,\n",
       "  3892,\n",
       "  1711,\n",
       "  3668,\n",
       "  6045,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [0],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'Tot_gc': (<keras.models.Sequential at 0x12e3f79e8>,\n",
       "  0.67041002874369404,\n",
       "  0.82167976830781964,\n",
       "  0.6134047153299701,\n",
       "  4310,\n",
       "  1293,\n",
       "  3755,\n",
       "  5958,\n",
       "  array([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'Total_GC': (<keras.models.Sequential at 0x15e5104e0>,\n",
       "  0.63809088534865499,\n",
       "  0.63726135615536539,\n",
       "  0.99660249150622882,\n",
       "  93,\n",
       "  5510,\n",
       "  33,\n",
       "  9680,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " \"align5'\": (<keras.models.Sequential at 0x15bb97588>,\n",
       "  0.63417341342387046,\n",
       "  0.63417341342387046,\n",
       "  1.0,\n",
       "  0,\n",
       "  5603,\n",
       "  0,\n",
       "  9713,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'binding_region_length': (<keras.models.Sequential at 0x129963160>,\n",
       "  0.63417341342387046,\n",
       "  0.63417341342387046,\n",
       "  1.0,\n",
       "  0,\n",
       "  5603,\n",
       "  0,\n",
       "  9713,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'd5': (<keras.models.Sequential at 0x162690828>,\n",
       "  0.63593627579002354,\n",
       "  0.635293348158807,\n",
       "  1.0,\n",
       "  27,\n",
       "  5576,\n",
       "  0,\n",
       "  9713,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'longest_consecutive_pairings': (<keras.models.Sequential at 0x12dc75c18>,\n",
       "  0.63410812222512403,\n",
       "  0.63453604871979574,\n",
       "  0.9976320395346443,\n",
       "  22,\n",
       "  5581,\n",
       "  23,\n",
       "  9690,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'm/e': (<keras.models.Sequential at 0x1338faa58>,\n",
       "  0.80699921652118167,\n",
       "  0.81518798395372705,\n",
       "  0.89961906722948626,\n",
       "  3622,\n",
       "  1981,\n",
       "  975,\n",
       "  8738,\n",
       "  array([[1],\n",
       "         [0],\n",
       "         [1],\n",
       "         ..., \n",
       "         [0],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'mRNA': (<keras.models.Sequential at 0x160b7acf8>,\n",
       "  0.63417341342387046,\n",
       "  0.63417341342387046,\n",
       "  1.0,\n",
       "  0,\n",
       "  5603,\n",
       "  0,\n",
       "  9713,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'miRNA': (<keras.models.Sequential at 0x16197ac88>,\n",
       "  0.6995951945677723,\n",
       "  0.68871825162433553,\n",
       "  0.96036240090600222,\n",
       "  1387,\n",
       "  4216,\n",
       "  385,\n",
       "  9328,\n",
       "  array([[1],\n",
       "         [0],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'number_of_pairings': (<keras.models.Sequential at 0x162f7c3c8>,\n",
       "  0.63417341342387046,\n",
       "  0.63417341342387046,\n",
       "  1.0,\n",
       "  0,\n",
       "  5603,\n",
       "  0,\n",
       "  9713,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'numirna': (<keras.models.Sequential at 0x160938198>,\n",
       "  0.63384695743013841,\n",
       "  0.63405394814185878,\n",
       "  0.99948522598579226,\n",
       "  0,\n",
       "  5603,\n",
       "  5,\n",
       "  9708,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'pairings_in_3prime_end': (<keras.models.Sequential at 0x158282c88>,\n",
       "  0.86308435621321378,\n",
       "  0.85213611984464588,\n",
       "  0.94872850818490684,\n",
       "  4004,\n",
       "  1599,\n",
       "  498,\n",
       "  9215,\n",
       "  array([[1],\n",
       "         [0],\n",
       "         [0],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=int32)),\n",
       " 'position_of_longest_consecutive_pairings': (<keras.models.Sequential at 0x11ef43da0>,\n",
       "  0.65715591536703977,\n",
       "  0.69955277280858674,\n",
       "  0.80520951302378252,\n",
       "  2244,\n",
       "  3359,\n",
       "  1892,\n",
       "  7821,\n",
       "  array([[1],\n",
       "         [1],\n",
       "         [0],\n",
       "         ..., \n",
       "         [1],\n",
       "         [1],\n",
       "         [0]], dtype=int32))}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LassoDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Our FInal Model is DNN on LASSO Features \n",
    "###### So we gonna apply DNN on LASSO Features and return the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Input[commonLassoFeatures],output, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "35736/35736 [==============================] - 7s 198us/step - loss: 0.6796 - acc: 0.7152\n",
      "Epoch 2/32\n",
      "35736/35736 [==============================] - 2s 68us/step - loss: 0.3836 - acc: 0.8187\n",
      "Epoch 3/32\n",
      "35736/35736 [==============================] - 2s 67us/step - loss: 0.3455 - acc: 0.8502\n",
      "Epoch 4/32\n",
      "35736/35736 [==============================] - 3s 71us/step - loss: 0.2835 - acc: 0.8791\n",
      "Epoch 5/32\n",
      "35736/35736 [==============================] - 3s 77us/step - loss: 0.2778 - acc: 0.9082\n",
      "Epoch 6/32\n",
      "35736/35736 [==============================] - 3s 79us/step - loss: 0.2072 - acc: 0.9212\n",
      "Epoch 7/32\n",
      "35736/35736 [==============================] - 3s 80us/step - loss: 0.1749 - acc: 0.9427\n",
      "Epoch 8/32\n",
      "35736/35736 [==============================] - 3s 83us/step - loss: 0.1602 - acc: 0.9527\n",
      "Epoch 9/32\n",
      "35736/35736 [==============================] - 3s 87us/step - loss: 0.1333 - acc: 0.9661\n",
      "Epoch 10/32\n",
      "35736/35736 [==============================] - 3s 86us/step - loss: 0.1053 - acc: 0.9689\n",
      "Epoch 11/32\n",
      "35736/35736 [==============================] - 3s 87us/step - loss: 0.1061 - acc: 0.9734\n",
      "Epoch 12/32\n",
      "35736/35736 [==============================] - 3s 94us/step - loss: 0.0877 - acc: 0.9759\n",
      "Epoch 13/32\n",
      "35736/35736 [==============================] - 3s 96us/step - loss: 0.1377 - acc: 0.9694\n",
      "Epoch 14/32\n",
      "35736/35736 [==============================] - 4s 100us/step - loss: 0.0987 - acc: 0.9812\n",
      "Epoch 15/32\n",
      "35736/35736 [==============================] - 4s 99us/step - loss: 0.1275 - acc: 0.9776\n",
      "Epoch 16/32\n",
      "35736/35736 [==============================] - 3s 92us/step - loss: 0.0880 - acc: 0.9808\n",
      "Epoch 17/32\n",
      "35736/35736 [==============================] - 3s 86us/step - loss: 0.0834 - acc: 0.9820\n",
      "Epoch 18/32\n",
      "35736/35736 [==============================] - 3s 85us/step - loss: 0.0896 - acc: 0.9826\n",
      "Epoch 19/32\n",
      "35736/35736 [==============================] - 3s 83us/step - loss: 0.1063 - acc: 0.9825\n",
      "Epoch 20/32\n",
      "35736/35736 [==============================] - 3s 79us/step - loss: 0.1574 - acc: 0.9771\n",
      "Epoch 21/32\n",
      "35736/35736 [==============================] - 3s 80us/step - loss: 0.1120 - acc: 0.9777\n",
      "Epoch 22/32\n",
      "35736/35736 [==============================] - 3s 78us/step - loss: 0.1445 - acc: 0.9768\n",
      "Epoch 23/32\n",
      "35736/35736 [==============================] - 3s 81us/step - loss: 0.1714 - acc: 0.9776\n",
      "Epoch 24/32\n",
      "35736/35736 [==============================] - 3s 77us/step - loss: 0.0996 - acc: 0.9813\n",
      "Epoch 25/32\n",
      "35736/35736 [==============================] - 3s 80us/step - loss: 7.3069 - acc: 0.5436\n",
      "Epoch 26/32\n",
      "35736/35736 [==============================] - 3s 80us/step - loss: 10.3061 - acc: 0.3606\n",
      "Epoch 27/32\n",
      "35736/35736 [==============================] - 3s 78us/step - loss: 10.3061 - acc: 0.3606\n",
      "Epoch 28/32\n",
      "35736/35736 [==============================] - 3s 82us/step - loss: 10.3061 - acc: 0.3606\n",
      "Epoch 29/32\n",
      "35736/35736 [==============================] - 3s 86us/step - loss: 10.3061 - acc: 0.3606\n",
      "Epoch 30/32\n",
      "35736/35736 [==============================] - 3s 86us/step - loss: 10.3061 - acc: 0.3606\n",
      "Epoch 31/32\n",
      "35736/35736 [==============================] - 3s 88us/step - loss: 10.3061 - acc: 0.3606\n",
      "Epoch 32/32\n",
      "35736/35736 [==============================] - 3s 90us/step - loss: 10.3061 - acc: 0.3606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15316/15316 [==============================] - 2s 138us/step\n"
     ]
    }
   ],
   "source": [
    "model,score, precision, recall, TN, FP, FN, TP, yPredict=DNN(np.array(X_train), np.array(y_train)\n",
    "                    , \n",
    "                    np.array(X_test),np.array(y_test)\n",
    "                    ,len(commonLassoFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pre=pd.DataFrame(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Prediction Probablity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_prob = model.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "pd.options.display.float_format = '{:,.20f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_array=np.transpose(np.array(y_predicted_prob))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pre[\"Prediction Probablity\"]=predicted_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Number values of miRNA and MRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'miRNA_info.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-a8ae2142e694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_miRNA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"miRNA_info.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    703\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1682\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'miRNA_info.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df_miRNA = pd.read_csv(\"miRNA_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miRNA.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mRNA = pd.read_csv(\"mRNA_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_Prediction =df_pre[[\"miRNA\",\"mRNA\",\"binding_region_length\",\"Prediction Probablity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_Prediction[\"miRNA\"]=cross_Prediction[\"miRNA\"].replace(list(df_miRNA[\"number\"]),list(df_miRNA[\"value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_Prediction[\"mRNA\"]=cross_Prediction[\"mRNA\"].replace(list(df_mRNA[\"number\"]),list(df_mRNA[\"value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_Prediction.to_csv(\"Predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_Prediction"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
